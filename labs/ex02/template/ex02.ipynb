{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    return np.sum((y - tx@w)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(53889667.317741685)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([1, 2])\n",
    "compute_loss(y, tx, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(grid_w0.shape[0]):\n",
    "        for j in range(grid_w1.shape[0]):\n",
    "            losses[i, j] = compute_loss(y, tx, np.array([grid_w0[i], grid_w1[j]]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=375870.82039046474, w0*=71.42857142857142, w1*=15.306122448979579, execution time=0.067 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return -1*np.dot(tx.T, (y - tx@w))/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=55844734.25518335, w0=51.30574540147367, w1=9.43579870449228\n",
      "GD iter. 1/49: loss=5306049.242179183, w0=66.69746902191577, w1=12.266538315840014\n",
      "GD iter. 2/49: loss=757567.5910088175, w0=71.31498610804836, w1=13.115760199244336\n",
      "GD iter. 3/49: loss=348204.2424034888, w0=72.70024123388815, w1=13.370526764265634\n",
      "GD iter. 4/49: loss=311361.541029009, w0=73.11581777164008, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=308045.6979053059, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=307747.2720241726, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=307720.4136948706, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=307717.99644523347, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=307717.7788927661, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=307717.759313044, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=307717.7575508691, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=307717.75739227334, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=307717.75737799966, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=307717.757376715, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=307717.7573765995, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=307717.757376589, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=307717.75737658807, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=307717.757376588, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=307717.75737658807, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=307717.75737658795, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=307717.757376588, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=307717.757376588, w0=73.2939220020362, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=307717.757376588, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=307717.757376588, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=307717.75737658795, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=307717.757376588, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=307717.757376588, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=307717.757376588, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=307717.757376588, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=307717.757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba79e46cbbe437fbb058b2cd6433efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    return -1*np.dot(tx.T, (y - tx@w))/y.shape[0]\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=55844734.25518335, w0=7.329392200210525, w1=1.3479712434988973\n",
      "SGD iter. 1/49: loss=45292701.12060005, w0=13.925845180399984, w1=2.561145362647906\n",
      "SGD iter. 2/49: loss=36745554.28158761, w0=19.862652862570528, w1=3.6530020698820116\n",
      "SGD iter. 3/49: loss=29822365.341987487, w0=25.205779776523993, w1=4.635673106392706\n",
      "SGD iter. 4/49: loss=24214582.30091142, w0=30.014593999082102, w1=5.520077039252338\n",
      "SGD iter. 5/49: loss=19672278.03763981, w0=34.34252679938441, w1=6.316040578826\n",
      "SGD iter. 6/49: loss=15993011.5843898, w0=38.2376663196565, w1=7.0324077644423\n",
      "SGD iter. 7/49: loss=13012805.757257283, w0=41.743291887901364, w1=7.677138231496971\n",
      "SGD iter. 8/49: loss=10598839.037279954, w0=44.898354899321745, w1=8.25739565184618\n",
      "SGD iter. 9/49: loss=8643525.994098315, w0=47.73791160960009, w1=8.779627330160464\n",
      "SGD iter. 10/49: loss=7059722.429121188, w0=50.29351264885061, w1=9.249635840643322\n",
      "SGD iter. 11/49: loss=5776841.541489709, w0=52.593553584176064, w1=9.67264350007789\n",
      "SGD iter. 12/49: loss=4737708.022508218, w0=54.66359042596898, w1=10.053350393569003\n",
      "SGD iter. 13/49: loss=3896009.872133208, w0=56.5266235835826, w1=10.395986597711007\n",
      "SGD iter. 14/49: loss=3214234.3703294504, w0=58.203353425434855, w1=10.704359181438807\n",
      "SGD iter. 15/49: loss=2661996.2138684075, w0=59.71241028310189, w1=10.981894506793829\n",
      "SGD iter. 16/49: loss=2214683.3071349617, w0=61.07056145500222, w1=11.231676299613351\n",
      "SGD iter. 17/49: loss=1852359.8526808703, w0=62.29289750971252, w1=11.45647991315092\n",
      "SGD iter. 18/49: loss=1558877.8545730566, w0=63.39299995895178, w1=11.658803165334731\n",
      "SGD iter. 19/49: loss=1321157.436105728, w0=64.38309216326712, w1=11.84089409230016\n",
      "SGD iter. 20/49: loss=1128603.8971471917, w0=65.27417514715093, w1=12.00477592656905\n",
      "SGD iter. 21/49: loss=972635.5305907772, w0=66.07614983264635, w1=12.152269577411047\n",
      "SGD iter. 22/49: loss=846301.1536800818, w0=66.79792704959223, w1=12.285013863168848\n",
      "SGD iter. 23/49: loss=743970.3083824184, w0=67.44752654484353, w1=12.404483720350868\n",
      "SGD iter. 24/49: loss=661082.3236913106, w0=68.03216609056969, w1=12.512006591814684\n",
      "SGD iter. 25/49: loss=593943.0560915138, w0=68.55834168172323, w1=12.608777176132119\n",
      "SGD iter. 26/49: loss=539560.2493356784, w0=69.03189971376143, w1=12.69587070201781\n",
      "SGD iter. 27/49: loss=495510.175863451, w0=69.45810194259582, w1=12.774254875314934\n",
      "SGD iter. 28/49: loss=459829.61635094637, w0=69.84168394854676, w1=12.844800631282345\n",
      "SGD iter. 29/49: loss=430928.36314581794, w0=70.1869077539026, w1=12.908291811653015\n",
      "SGD iter. 30/49: loss=407518.3480496643, w0=70.49760917872285, w1=12.965433873986619\n",
      "SGD iter. 31/49: loss=388556.23582178017, w0=70.77724046106108, w1=13.016861730086863\n",
      "SGD iter. 32/49: loss=373196.9249171939, w0=71.02890861516549, w1=13.06314680057708\n",
      "SGD iter. 33/49: loss=360755.8830844789, w0=71.25540995385946, w1=13.104803364018277\n",
      "SGD iter. 34/49: loss=350678.63919997984, w0=71.45926115868403, w1=13.142294271115354\n",
      "SGD iter. 35/49: loss=342516.07165353536, w0=71.64272724302614, w1=13.176036087502723\n",
      "SGD iter. 36/49: loss=335904.3919409155, w0=71.80784671893404, w1=13.206403722251356\n",
      "SGD iter. 37/49: loss=330548.9313736933, w0=71.95645424725116, w1=13.233734593525124\n",
      "SGD iter. 38/49: loss=326211.0083142433, w0=72.09020102273657, w1=13.258332377671517\n",
      "SGD iter. 39/49: loss=322697.2906360887, w0=72.21057312067343, w1=13.28047038340327\n",
      "SGD iter. 40/49: loss=319851.17931678356, w0=72.3189080088166, w1=13.300394588561847\n",
      "SGD iter. 41/49: loss=317545.8291481464, w0=72.41640940814547, w1=13.318326373204567\n",
      "SGD iter. 42/49: loss=315678.49551155017, w0=72.50416066754144, w1=13.334464979383014\n",
      "SGD iter. 43/49: loss=314165.9552659074, w0=72.58313680099782, w1=13.348989724943618\n",
      "SGD iter. 44/49: loss=312940.79766693665, w0=72.65421532110855, w1=13.36206199594816\n",
      "SGD iter. 45/49: loss=311948.4200117705, w0=72.71818598920821, w1=13.373827039852248\n",
      "SGD iter. 46/49: loss=311144.59411108587, w0=72.77575959049791, w1=13.384415579365928\n",
      "SGD iter. 47/49: loss=310493.4951315312, w0=72.82757583165863, w1=13.39394526492824\n",
      "SGD iter. 48/49: loss=309966.10495809204, w0=72.8742104487033, w1=13.40252198193432\n",
      "SGD iter. 49/49: loss=309538.91891760624, w0=72.91618160404349, w1=13.410241027239794\n",
      "SGD: execution time=0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f2b57492744ec4b51ac0099d30c6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=1131708.8897753665, w0=51.542590721811806, w1=10.132993413506094\n",
      "SGD iter. 1/49: loss=106820.01035117678, w0=67.00536793835533, w1=13.17289143755783\n",
      "SGD iter. 2/49: loss=14580.011203000104, w0=71.64420110331838, w1=14.084860844773326\n",
      "SGD iter. 3/49: loss=6278.411279664253, w0=73.03585105280729, w1=14.358451666937965\n",
      "SGD iter. 4/49: loss=5531.267286564031, w0=73.45334603765397, w1=14.440528913587356\n",
      "SGD iter. 5/49: loss=5464.024327185009, w0=73.57859453310797, w1=14.46515208758217\n",
      "SGD iter. 6/49: loss=5457.972460840897, w0=73.61616908174418, w1=14.472539039780616\n",
      "SGD iter. 7/49: loss=5457.427792869927, w0=73.62744144633503, w1=14.474755125440149\n",
      "SGD iter. 8/49: loss=5457.378772752541, w0=73.63082315571229, w1=14.47541995113801\n",
      "SGD iter. 9/49: loss=5457.374360941976, w0=73.63183766852546, w1=14.475619398847368\n",
      "SGD iter. 10/49: loss=5457.373963879024, w0=73.63214202236942, w1=14.475679233160175\n",
      "SGD iter. 11/49: loss=5457.373928143359, w0=73.6322333285226, w1=14.475697183454017\n",
      "SGD iter. 12/49: loss=5457.37392492715, w0=73.63226072036856, w1=14.47570256854217\n",
      "SGD iter. 13/49: loss=5457.373924637692, w0=73.63226893792235, w1=14.475704184068615\n",
      "SGD iter. 14/49: loss=5457.373924611638, w0=73.63227140318848, w1=14.475704668726548\n",
      "SGD iter. 15/49: loss=5457.373924609294, w0=73.63227214276833, w1=14.47570481412393\n",
      "SGD iter. 16/49: loss=5457.373924609083, w0=73.63227236464228, w1=14.475704857743143\n",
      "SGD iter. 17/49: loss=5457.373924609064, w0=73.63227243120446, w1=14.475704870828908\n",
      "SGD iter. 18/49: loss=5457.373924609063, w0=73.63227245117312, w1=14.475704874754637\n",
      "SGD iter. 19/49: loss=5457.373924609063, w0=73.63227245716372, w1=14.475704875932356\n",
      "SGD iter. 20/49: loss=5457.373924609061, w0=73.6322724589609, w1=14.475704876285672\n",
      "SGD iter. 21/49: loss=5457.373924609063, w0=73.63227245950004, w1=14.475704876391665\n",
      "SGD iter. 22/49: loss=5457.373924609063, w0=73.63227245966179, w1=14.475704876423464\n",
      "SGD iter. 23/49: loss=5457.373924609062, w0=73.63227245971032, w1=14.475704876433003\n",
      "SGD iter. 24/49: loss=5457.373924609063, w0=73.63227245972487, w1=14.475704876435865\n",
      "SGD iter. 25/49: loss=5457.373924609063, w0=73.63227245972924, w1=14.475704876436724\n",
      "SGD iter. 26/49: loss=5457.373924609062, w0=73.63227245973056, w1=14.475704876436982\n",
      "SGD iter. 27/49: loss=5457.373924609062, w0=73.63227245973094, w1=14.475704876437058\n",
      "SGD iter. 28/49: loss=5457.373924609063, w0=73.63227245973106, w1=14.475704876437081\n",
      "SGD iter. 29/49: loss=5457.373924609062, w0=73.6322724597311, w1=14.475704876437089\n",
      "SGD iter. 30/49: loss=5457.373924609063, w0=73.63227245973111, w1=14.47570487643709\n",
      "SGD iter. 31/49: loss=5457.373924609063, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 32/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 33/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 34/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 35/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 36/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 37/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 38/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 39/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 40/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 41/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 42/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 43/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 44/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 45/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 46/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 47/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 48/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "SGD iter. 49/49: loss=5457.373924609062, w0=73.63227245973111, w1=14.475704876437092\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b771c76d2740e6af0ce376320349e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    e = y - tx@w\n",
    "    mae_term = np.zeros((y.shape[0], 1))\n",
    "    mae_term[e > 0.0] = 1.0\n",
    "    mae_term[e < 0.0] = -1.0\n",
    "    # mae_term[e == 0.0] = 1.0\n",
    "    mae_term = mae_term.reshape((1, y.shape[0]))/y.shape[0]\n",
    "    return (-mae_term@tx).T[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = np.sum(np.abs(y - tx@w))\n",
    "        gradient = compute_subgradient_mae(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=14726.454491946228, w0=0.7000000000000004, w1=1.6830287163926981e-15\n",
      "SubGD iter. 1/499: loss=14586.454491946228, w0=1.4000000000000008, w1=3.3660574327853962e-15\n",
      "SubGD iter. 2/499: loss=14446.454491946228, w0=2.1000000000000014, w1=5.0490861491780946e-15\n",
      "SubGD iter. 3/499: loss=14306.454491946228, w0=2.8000000000000016, w1=6.7321148655707925e-15\n",
      "SubGD iter. 4/499: loss=14166.45449194623, w0=3.5000000000000018, w1=8.415143581963491e-15\n",
      "SubGD iter. 5/499: loss=14026.454491946228, w0=4.200000000000002, w1=1.0098172298356189e-14\n",
      "SubGD iter. 6/499: loss=13886.454491946228, w0=4.900000000000002, w1=1.1781201014748887e-14\n",
      "SubGD iter. 7/499: loss=13746.45449194623, w0=5.600000000000002, w1=1.3464229731141585e-14\n",
      "SubGD iter. 8/499: loss=13606.45449194623, w0=6.3000000000000025, w1=1.5147258447534283e-14\n",
      "SubGD iter. 9/499: loss=13466.45449194623, w0=7.000000000000003, w1=1.6830287163926982e-14\n",
      "SubGD iter. 10/499: loss=13326.45449194623, w0=7.700000000000003, w1=1.8513315880319682e-14\n",
      "SubGD iter. 11/499: loss=13186.454491946228, w0=8.400000000000004, w1=2.019634459671238e-14\n",
      "SubGD iter. 12/499: loss=13046.454491946228, w0=9.100000000000005, w1=2.187937331310508e-14\n",
      "SubGD iter. 13/499: loss=12906.45449194623, w0=9.800000000000006, w1=2.356240202949778e-14\n",
      "SubGD iter. 14/499: loss=12766.454491946228, w0=10.500000000000007, w1=2.524543074589048e-14\n",
      "SubGD iter. 15/499: loss=12626.454491946228, w0=11.200000000000008, w1=2.692845946228318e-14\n",
      "SubGD iter. 16/499: loss=12486.45449194623, w0=11.90000000000001, w1=2.861148817867588e-14\n",
      "SubGD iter. 17/499: loss=12346.454491946228, w0=12.60000000000001, w1=3.029451689506858e-14\n",
      "SubGD iter. 18/499: loss=12206.454491946228, w0=13.300000000000011, w1=3.197754561146128e-14\n",
      "SubGD iter. 19/499: loss=12066.454491946228, w0=14.000000000000012, w1=3.366057432785398e-14\n",
      "SubGD iter. 20/499: loss=11926.454491946228, w0=14.700000000000014, w1=3.534360304424668e-14\n",
      "SubGD iter. 21/499: loss=11786.454491946228, w0=15.400000000000015, w1=3.7026631760639376e-14\n",
      "SubGD iter. 22/499: loss=11646.454491946228, w0=16.100000000000016, w1=3.8709660477032076e-14\n",
      "SubGD iter. 23/499: loss=11506.454491946228, w0=16.800000000000015, w1=4.0392689193424776e-14\n",
      "SubGD iter. 24/499: loss=11366.454491946228, w0=17.500000000000014, w1=4.2075717909817475e-14\n",
      "SubGD iter. 25/499: loss=11226.454491946228, w0=18.200000000000014, w1=4.3758746626210175e-14\n",
      "SubGD iter. 26/499: loss=11086.454491946228, w0=18.900000000000013, w1=4.5441775342602874e-14\n",
      "SubGD iter. 27/499: loss=10946.454491946228, w0=19.600000000000012, w1=4.7124804058995574e-14\n",
      "SubGD iter. 28/499: loss=10806.454491946228, w0=20.30000000000001, w1=4.880783277538827e-14\n",
      "SubGD iter. 29/499: loss=10666.454491946228, w0=21.00000000000001, w1=5.049086149178097e-14\n",
      "SubGD iter. 30/499: loss=10526.454491946228, w0=21.70000000000001, w1=5.217389020817367e-14\n",
      "SubGD iter. 31/499: loss=10386.454491946228, w0=22.40000000000001, w1=5.385691892456637e-14\n",
      "SubGD iter. 32/499: loss=10246.454491946228, w0=23.10000000000001, w1=5.553994764095907e-14\n",
      "SubGD iter. 33/499: loss=10106.454491946228, w0=23.800000000000008, w1=5.722297635735177e-14\n",
      "SubGD iter. 34/499: loss=9966.454491946228, w0=24.500000000000007, w1=5.890600507374446e-14\n",
      "SubGD iter. 35/499: loss=9826.454491946228, w0=25.200000000000006, w1=6.058903379013716e-14\n",
      "SubGD iter. 36/499: loss=9686.454491946228, w0=25.900000000000006, w1=6.227206250652985e-14\n",
      "SubGD iter. 37/499: loss=9546.454491946228, w0=26.600000000000005, w1=6.395509122292254e-14\n",
      "SubGD iter. 38/499: loss=9406.454491946228, w0=27.300000000000004, w1=6.563811993931524e-14\n",
      "SubGD iter. 39/499: loss=9266.454491946228, w0=28.000000000000004, w1=6.732114865570793e-14\n",
      "SubGD iter. 40/499: loss=9126.45449194623, w0=28.700000000000003, w1=6.900417737210062e-14\n",
      "SubGD iter. 41/499: loss=8986.454491946228, w0=29.400000000000002, w1=7.068720608849332e-14\n",
      "SubGD iter. 42/499: loss=8846.45449194623, w0=30.1, w1=7.237023480488601e-14\n",
      "SubGD iter. 43/499: loss=8706.45449194623, w0=30.8, w1=7.40532635212787e-14\n",
      "SubGD iter. 44/499: loss=8566.45449194623, w0=31.5, w1=7.57362922376714e-14\n",
      "SubGD iter. 45/499: loss=8426.45449194623, w0=32.2, w1=7.741932095406409e-14\n",
      "SubGD iter. 46/499: loss=8286.45449194623, w0=32.900000000000006, w1=7.910234967045678e-14\n",
      "SubGD iter. 47/499: loss=8146.454491946229, w0=33.60000000000001, w1=8.078537838684948e-14\n",
      "SubGD iter. 48/499: loss=8006.454491946228, w0=34.30000000000001, w1=8.246840710324217e-14\n",
      "SubGD iter. 49/499: loss=7866.454491946228, w0=35.000000000000014, w1=8.415143581963486e-14\n",
      "SubGD iter. 50/499: loss=7726.454491946226, w0=35.70000000000002, w1=8.583446453602755e-14\n",
      "SubGD iter. 51/499: loss=7586.454491946227, w0=36.40000000000002, w1=8.751749325242025e-14\n",
      "SubGD iter. 52/499: loss=7446.454491946226, w0=37.10000000000002, w1=8.920052196881294e-14\n",
      "SubGD iter. 53/499: loss=7306.454491946224, w0=37.800000000000026, w1=9.088355068520563e-14\n",
      "SubGD iter. 54/499: loss=7166.454491946224, w0=38.50000000000003, w1=9.256657940159833e-14\n",
      "SubGD iter. 55/499: loss=7026.454491946224, w0=39.20000000000003, w1=9.424960811799102e-14\n",
      "SubGD iter. 56/499: loss=6886.454491946224, w0=39.900000000000034, w1=9.593263683438371e-14\n",
      "SubGD iter. 57/499: loss=6746.454491946222, w0=40.60000000000004, w1=9.761566555077641e-14\n",
      "SubGD iter. 58/499: loss=6606.454491946222, w0=41.30000000000004, w1=9.92986942671691e-14\n",
      "SubGD iter. 59/499: loss=6466.4544919462205, w0=42.00000000000004, w1=1.0098172298356179e-13\n",
      "SubGD iter. 60/499: loss=6326.454491946222, w0=42.700000000000045, w1=1.0266475169995449e-13\n",
      "SubGD iter. 61/499: loss=6186.454491946221, w0=43.40000000000005, w1=1.0434778041634718e-13\n",
      "SubGD iter. 62/499: loss=6046.4544919462205, w0=44.10000000000005, w1=1.0603080913273987e-13\n",
      "SubGD iter. 63/499: loss=5906.45449194622, w0=44.800000000000054, w1=1.0771383784913257e-13\n",
      "SubGD iter. 64/499: loss=5766.454491946219, w0=45.50000000000006, w1=1.0939686656552526e-13\n",
      "SubGD iter. 65/499: loss=5626.454491946219, w0=46.20000000000006, w1=1.1107989528191795e-13\n",
      "SubGD iter. 66/499: loss=5486.454491946217, w0=46.90000000000006, w1=1.1276292399831065e-13\n",
      "SubGD iter. 67/499: loss=5347.5582916042185, w0=47.59300000000006, w1=0.012822729222840914\n",
      "SubGD iter. 68/499: loss=5211.006733095646, w0=48.27900000000006, w1=0.038067565076885634\n",
      "SubGD iter. 69/499: loss=5076.368646884989, w0=48.96500000000006, w1=0.06331240093093035\n",
      "SubGD iter. 70/499: loss=4943.821025116397, w0=49.63000000000006, w1=0.12140253076845614\n",
      "SubGD iter. 71/499: loss=4817.424201213635, w0=50.28800000000006, w1=0.19295915708008107\n",
      "SubGD iter. 72/499: loss=4692.257243851034, w0=50.94600000000006, w1=0.264515783391706\n",
      "SubGD iter. 73/499: loss=4568.651429724951, w0=51.59000000000006, w1=0.36003710381024756\n",
      "SubGD iter. 74/499: loss=4448.224392503597, w0=52.22000000000006, w1=0.47488016550951084\n",
      "SubGD iter. 75/499: loss=4331.057210988867, w0=52.84300000000006, w1=0.6005235649987747\n",
      "SubGD iter. 76/499: loss=4215.879166545817, w0=53.45900000000006, w1=0.735466325292314\n",
      "SubGD iter. 77/499: loss=4102.969177162323, w0=54.06800000000006, w1=0.8798253451603704\n",
      "SubGD iter. 78/499: loss=3992.2250635251867, w0=54.66300000000006, w1=1.0417652853159154\n",
      "SubGD iter. 79/499: loss=3883.582336605878, w0=55.25800000000006, w1=1.2037052254714604\n",
      "SubGD iter. 80/499: loss=3775.647382158899, w0=55.83900000000006, w1=1.3822638190738594\n",
      "SubGD iter. 81/499: loss=3670.6913195125335, w0=56.41300000000006, w1=1.5664626351241269\n",
      "SubGD iter. 82/499: loss=3568.810467979312, w0=56.95200000000006, w1=1.787159964971011\n",
      "SubGD iter. 83/499: loss=3472.3432387153216, w0=57.484000000000066, w1=2.01383512121847\n",
      "SubGD iter. 84/499: loss=3376.7987740125177, w0=58.01600000000007, w1=2.240510277465929\n",
      "SubGD iter. 85/499: loss=3282.7227005301247, w0=58.51300000000007, w1=2.4977608864129515\n",
      "SubGD iter. 86/499: loss=3193.240736014806, w0=59.01000000000007, w1=2.755011495359974\n",
      "SubGD iter. 87/499: loss=3104.6213704263396, w0=59.493000000000066, w1=3.0191142997242326\n",
      "SubGD iter. 88/499: loss=3018.0387157768932, w0=59.97600000000006, w1=3.283217104088491\n",
      "SubGD iter. 89/499: loss=2932.1170483974884, w0=60.45200000000006, w1=3.547812933905622\n",
      "SubGD iter. 90/499: loss=2847.946606167452, w0=60.893000000000065, w1=3.8427091128559843\n",
      "SubGD iter. 91/499: loss=2768.053488940173, w0=61.320000000000064, w1=4.148442254175183\n",
      "SubGD iter. 92/499: loss=2689.3793402521887, w0=61.740000000000066, w1=4.458787226613842\n",
      "SubGD iter. 93/499: loss=2611.4610539899168, w0=62.16000000000007, w1=4.7691321990525015\n",
      "SubGD iter. 94/499: loss=2533.542767727645, w0=62.58000000000007, w1=5.079477171491161\n",
      "SubGD iter. 95/499: loss=2456.5439798122916, w0=62.97900000000007, w1=5.401328404320425\n",
      "SubGD iter. 96/499: loss=2381.9480059927632, w0=63.37100000000007, w1=5.725928703251704\n",
      "SubGD iter. 97/499: loss=2308.0876493140768, w0=63.74900000000007, w1=6.061744039727746\n",
      "SubGD iter. 98/499: loss=2235.098420626792, w0=64.12000000000008, w1=6.401747716728321\n",
      "SubGD iter. 99/499: loss=2162.7431348056743, w0=64.49100000000007, w1=6.741751393728897\n",
      "SubGD iter. 100/499: loss=2090.6375545806027, w0=64.87600000000008, w1=7.061378131166483\n",
      "SubGD iter. 101/499: loss=2019.5845075670195, w0=65.24700000000007, w1=7.38752359388077\n",
      "SubGD iter. 102/499: loss=1949.8668324672722, w0=65.61800000000007, w1=7.713669056595057\n",
      "SubGD iter. 103/499: loss=1880.2483470148386, w0=65.98200000000007, w1=8.040435506798632\n",
      "SubGD iter. 104/499: loss=1812.1298841840376, w0=66.34600000000007, w1=8.353859837656556\n",
      "SubGD iter. 105/499: loss=1746.4006548551508, w0=66.71700000000007, w1=8.653513683656954\n",
      "SubGD iter. 106/499: loss=1681.9160483895998, w0=67.08100000000007, w1=8.955524223771471\n",
      "SubGD iter. 107/499: loss=1618.140453250564, w0=67.43800000000007, w1=9.25498501711051\n",
      "SubGD iter. 108/499: loss=1556.2651523864465, w0=67.78100000000008, w1=9.560846653934\n",
      "SubGD iter. 109/499: loss=1496.7592255253683, w0=68.11700000000008, w1=9.860337267127163\n",
      "SubGD iter. 110/499: loss=1439.9601430154758, w0=68.43200000000007, w1=10.156521139455208\n",
      "SubGD iter. 111/499: loss=1386.6527757932383, w0=68.74700000000007, w1=10.44445347734849\n",
      "SubGD iter. 112/499: loss=1335.6241282326146, w0=69.03400000000008, w1=10.743406876764546\n",
      "SubGD iter. 113/499: loss=1287.0324873064683, w0=69.31400000000008, w1=11.038005391074634\n",
      "SubGD iter. 114/499: loss=1240.9197621286332, w0=69.59400000000008, w1=11.313287847901128\n",
      "SubGD iter. 115/499: loss=1197.8246319572079, w0=69.86700000000008, w1=11.578413278202849\n",
      "SubGD iter. 116/499: loss=1156.4473480164443, w0=70.14000000000007, w1=11.84353870850457\n",
      "SubGD iter. 117/499: loss=1115.519407789417, w0=70.39900000000007, w1=12.104101240231255\n",
      "SubGD iter. 118/499: loss=1077.1524301779511, w0=70.65100000000007, w1=12.36722983468918\n",
      "SubGD iter. 119/499: loss=1039.5455769657992, w0=70.90300000000006, w1=12.607410619209126\n",
      "SubGD iter. 120/499: loss=1005.7298171408189, w0=71.14800000000007, w1=12.829819894660053\n",
      "SubGD iter. 121/499: loss=975.0141283425196, w0=71.37900000000006, w1=13.051299546685472\n",
      "SubGD iter. 122/499: loss=947.005951176285, w0=71.59600000000006, w1=13.253978279130127\n",
      "SubGD iter. 123/499: loss=922.951196549194, w0=71.80600000000005, w1=13.44375255576234\n",
      "SubGD iter. 124/499: loss=901.4425616297469, w0=71.98100000000005, w1=13.60001256733913\n",
      "SubGD iter. 125/499: loss=888.2351261015862, w0=72.12100000000005, w1=13.709638751573955\n",
      "SubGD iter. 126/499: loss=879.2254392589161, w0=72.25400000000005, w1=13.823710297553665\n",
      "SubGD iter. 127/499: loss=871.4570898839752, w0=72.35900000000005, w1=13.928950177753492\n",
      "SubGD iter. 128/499: loss=865.2751251926044, w0=72.45700000000005, w1=14.033063640618643\n",
      "SubGD iter. 129/499: loss=860.085960553727, w0=72.53400000000005, w1=14.118590076651575\n",
      "SubGD iter. 130/499: loss=856.3020259078714, w0=72.61100000000005, w1=14.204116512684507\n",
      "SubGD iter. 131/499: loss=852.9488952284264, w0=72.66700000000004, w1=14.262362322468729\n",
      "SubGD iter. 132/499: loss=851.110855996505, w0=72.71600000000005, w1=14.31250818978189\n",
      "SubGD iter. 133/499: loss=849.7063965654795, w0=72.76500000000006, w1=14.362654057095053\n",
      "SubGD iter. 134/499: loss=848.301937134454, w0=72.81400000000006, w1=14.412799924408215\n",
      "SubGD iter. 135/499: loss=846.8974777034284, w0=72.86300000000007, w1=14.462945791721378\n",
      "SubGD iter. 136/499: loss=845.5295902476282, w0=72.91900000000007, w1=14.500669552403224\n",
      "SubGD iter. 137/499: loss=844.38790536032, w0=72.96100000000007, w1=14.528246426173608\n",
      "SubGD iter. 138/499: loss=843.6670445700101, w0=73.01000000000008, w1=14.543000570721267\n",
      "SubGD iter. 139/499: loss=842.9928828207533, w0=73.04500000000007, w1=14.568377913364845\n",
      "SubGD iter. 140/499: loss=842.5634122278454, w0=73.07300000000008, w1=14.586058146365021\n",
      "SubGD iter. 141/499: loss=842.2501006167196, w0=73.10100000000008, w1=14.603738379365197\n",
      "SubGD iter. 142/499: loss=841.9367890055937, w0=73.12900000000009, w1=14.621418612365373\n",
      "SubGD iter. 143/499: loss=841.6292467988933, w0=73.16400000000009, w1=14.626276116142824\n",
      "SubGD iter. 144/499: loss=841.3963068271992, w0=73.18500000000009, w1=14.637490968842984\n",
      "SubGD iter. 145/499: loss=841.2343717068886, w0=73.20600000000009, w1=14.648705821543144\n",
      "SubGD iter. 146/499: loss=841.0724365865782, w0=73.22700000000009, w1=14.659920674243304\n",
      "SubGD iter. 147/499: loss=840.910501466268, w0=73.24800000000009, w1=14.671135526943464\n",
      "SubGD iter. 148/499: loss=840.7485663459574, w0=73.26900000000009, w1=14.682350379643625\n",
      "SubGD iter. 149/499: loss=840.5866312256471, w0=73.29000000000009, w1=14.693565232343785\n",
      "SubGD iter. 150/499: loss=840.4334388338245, w0=73.30400000000009, w1=14.703897822273008\n",
      "SubGD iter. 151/499: loss=840.3874504846104, w0=73.30400000000009, w1=14.699292575283696\n",
      "SubGD iter. 152/499: loss=840.3951663570733, w0=73.30400000000009, w1=14.71264121692516\n",
      "SubGD iter. 153/499: loss=840.3989549108671, w0=73.30400000000009, w1=14.708035969935848\n",
      "SubGD iter. 154/499: loss=840.3928953966292, w0=73.30400000000009, w1=14.703430722946536\n",
      "SubGD iter. 155/499: loss=840.3874785633539, w0=73.31100000000009, w1=14.704357257956683\n",
      "SubGD iter. 156/499: loss=840.3906718920142, w0=73.30400000000009, w1=14.712174117598687\n",
      "SubGD iter. 157/499: loss=840.3983403086479, w0=73.30400000000009, w1=14.707568870609375\n",
      "SubGD iter. 158/499: loss=840.39228079441, w0=73.30400000000009, w1=14.702963623620063\n",
      "SubGD iter. 159/499: loss=840.3876022158906, w0=73.31100000000009, w1=14.70389015863021\n",
      "SubGD iter. 160/499: loss=840.391715106264, w0=73.30400000000009, w1=14.711707018272214\n",
      "SubGD iter. 161/499: loss=840.3977257064289, w0=73.30400000000009, w1=14.707101771282902\n",
      "SubGD iter. 162/499: loss=840.3916661921911, w0=73.30400000000009, w1=14.70249652429359\n",
      "SubGD iter. 163/499: loss=840.3877258684277, w0=73.31100000000009, w1=14.703423059303738\n",
      "SubGD iter. 164/499: loss=840.3927583205136, w0=73.30400000000009, w1=14.711239918945742\n",
      "SubGD iter. 165/499: loss=840.3971111042097, w0=73.30400000000009, w1=14.70663467195643\n",
      "SubGD iter. 166/499: loss=840.391051589972, w0=73.30400000000009, w1=14.702029424967117\n",
      "SubGD iter. 167/499: loss=840.3878495209646, w0=73.31100000000009, w1=14.702955959977265\n",
      "SubGD iter. 168/499: loss=840.3938015347633, w0=73.30400000000009, w1=14.710772819619269\n",
      "SubGD iter. 169/499: loss=840.3964965019907, w0=73.30400000000009, w1=14.706167572629957\n",
      "SubGD iter. 170/499: loss=840.3904369877528, w0=73.30400000000009, w1=14.701562325640644\n",
      "SubGD iter. 171/499: loss=840.3879731735015, w0=73.31100000000009, w1=14.702488860650792\n",
      "SubGD iter. 172/499: loss=840.3948447490131, w0=73.30400000000009, w1=14.710305720292796\n",
      "SubGD iter. 173/499: loss=840.3958818997714, w0=73.30400000000009, w1=14.705700473303484\n",
      "SubGD iter. 174/499: loss=840.3898223855336, w0=73.30400000000009, w1=14.701095226314171\n",
      "SubGD iter. 175/499: loss=840.3882912306133, w0=73.30400000000009, w1=14.714443867955636\n",
      "SubGD iter. 176/499: loss=840.4013268117903, w0=73.30400000000009, w1=14.709838620966323\n",
      "SubGD iter. 177/499: loss=840.3952672975523, w0=73.30400000000009, w1=14.705233373977011\n",
      "SubGD iter. 178/499: loss=840.3892077833145, w0=73.30400000000009, w1=14.700628126987699\n",
      "SubGD iter. 179/499: loss=840.3900726996189, w0=73.30400000000009, w1=14.713976768629163\n",
      "SubGD iter. 180/499: loss=840.4007122095711, w0=73.30400000000009, w1=14.70937152163985\n",
      "SubGD iter. 181/499: loss=840.3946526953334, w0=73.30400000000009, w1=14.704766274650538\n",
      "SubGD iter. 182/499: loss=840.3885931810953, w0=73.30400000000009, w1=14.700161027661226\n",
      "SubGD iter. 183/499: loss=840.3918541686246, w0=73.30400000000009, w1=14.71350966930269\n",
      "SubGD iter. 184/499: loss=840.4000976073519, w0=73.30400000000009, w1=14.708904422313378\n",
      "SubGD iter. 185/499: loss=840.394038093114, w0=73.30400000000009, w1=14.704299175324065\n",
      "SubGD iter. 186/499: loss=840.3879785788763, w0=73.30400000000009, w1=14.699693928334753\n",
      "SubGD iter. 187/499: loss=840.3936356376304, w0=73.30400000000009, w1=14.713042569976217\n",
      "SubGD iter. 188/499: loss=840.3994830051329, w0=73.30400000000009, w1=14.708437322986905\n",
      "SubGD iter. 189/499: loss=840.3934234908949, w0=73.30400000000009, w1=14.703832075997592\n",
      "SubGD iter. 190/499: loss=840.3873723154529, w0=73.31100000000009, w1=14.70475861100774\n",
      "SubGD iter. 191/499: loss=840.389775514738, w0=73.30400000000009, w1=14.712575470649744\n",
      "SubGD iter. 192/499: loss=840.3988684029136, w0=73.30400000000009, w1=14.707970223660432\n",
      "SubGD iter. 193/499: loss=840.3928088886759, w0=73.30400000000009, w1=14.70336497667112\n",
      "SubGD iter. 194/499: loss=840.3874959679897, w0=73.31100000000009, w1=14.704291511681268\n",
      "SubGD iter. 195/499: loss=840.3908187289876, w0=73.30400000000009, w1=14.712108371323271\n",
      "SubGD iter. 196/499: loss=840.3982538006946, w0=73.30400000000009, w1=14.70750312433396\n",
      "SubGD iter. 197/499: loss=840.3921942864566, w0=73.30400000000009, w1=14.702897877344647\n",
      "SubGD iter. 198/499: loss=840.3876196205267, w0=73.31100000000009, w1=14.703824412354795\n",
      "SubGD iter. 199/499: loss=840.3918619432372, w0=73.30400000000009, w1=14.711641271996799\n",
      "SubGD iter. 200/499: loss=840.3976391984755, w0=73.30400000000009, w1=14.707036025007486\n",
      "SubGD iter. 201/499: loss=840.3915796842375, w0=73.30400000000009, w1=14.702430778018174\n",
      "SubGD iter. 202/499: loss=840.3877432730636, w0=73.31100000000009, w1=14.703357313028322\n",
      "SubGD iter. 203/499: loss=840.392905157487, w0=73.30400000000009, w1=14.711174172670326\n",
      "SubGD iter. 204/499: loss=840.3970245962564, w0=73.30400000000009, w1=14.706568925681013\n",
      "SubGD iter. 205/499: loss=840.3909650820185, w0=73.30400000000009, w1=14.701963678691701\n",
      "SubGD iter. 206/499: loss=840.3878669256004, w0=73.31100000000009, w1=14.70289021370185\n",
      "SubGD iter. 207/499: loss=840.3939483717368, w0=73.30400000000009, w1=14.710707073343853\n",
      "SubGD iter. 208/499: loss=840.3964099940372, w0=73.30400000000009, w1=14.70610182635454\n",
      "SubGD iter. 209/499: loss=840.3903504797994, w0=73.30400000000009, w1=14.701496579365228\n",
      "SubGD iter. 210/499: loss=840.3879905781374, w0=73.31100000000009, w1=14.702423114375376\n",
      "SubGD iter. 211/499: loss=840.3949915859864, w0=73.30400000000009, w1=14.71023997401738\n",
      "SubGD iter. 212/499: loss=840.395795391818, w0=73.30400000000009, w1=14.705634727028068\n",
      "SubGD iter. 213/499: loss=840.3897358775803, w0=73.30400000000009, w1=14.701029480038756\n",
      "SubGD iter. 214/499: loss=840.388541980176, w0=73.30400000000009, w1=14.71437812168022\n",
      "SubGD iter. 215/499: loss=840.4012403038369, w0=73.30400000000009, w1=14.709772874690907\n",
      "SubGD iter. 216/499: loss=840.3951807895991, w0=73.30400000000009, w1=14.705167627701595\n",
      "SubGD iter. 217/499: loss=840.389121275361, w0=73.30400000000009, w1=14.700562380712283\n",
      "SubGD iter. 218/499: loss=840.3903234491818, w0=73.30400000000009, w1=14.713911022353747\n",
      "SubGD iter. 219/499: loss=840.4006257016177, w0=73.30400000000009, w1=14.709305775364435\n",
      "SubGD iter. 220/499: loss=840.3945661873798, w0=73.30400000000009, w1=14.704700528375122\n",
      "SubGD iter. 221/499: loss=840.3885066731419, w0=73.30400000000009, w1=14.70009528138581\n",
      "SubGD iter. 222/499: loss=840.3921049181874, w0=73.30400000000009, w1=14.713443923027274\n",
      "SubGD iter. 223/499: loss=840.4000110993986, w0=73.30400000000009, w1=14.708838676037962\n",
      "SubGD iter. 224/499: loss=840.3939515851607, w0=73.30400000000009, w1=14.70423342904865\n",
      "SubGD iter. 225/499: loss=840.3878920709228, w0=73.30400000000009, w1=14.699628182059337\n",
      "SubGD iter. 226/499: loss=840.3938863871932, w0=73.30400000000009, w1=14.712976823700801\n",
      "SubGD iter. 227/499: loss=840.3993964971795, w0=73.30400000000009, w1=14.708371576711489\n",
      "SubGD iter. 228/499: loss=840.3933369829417, w0=73.30400000000009, w1=14.703766329722177\n",
      "SubGD iter. 229/499: loss=840.387389720089, w0=73.31100000000009, w1=14.704692864732325\n",
      "SubGD iter. 230/499: loss=840.3899223517112, w0=73.30400000000009, w1=14.712509724374328\n",
      "SubGD iter. 231/499: loss=840.3987818949603, w0=73.30400000000009, w1=14.707904477385016\n",
      "SubGD iter. 232/499: loss=840.3927223807224, w0=73.30400000000009, w1=14.703299230395704\n",
      "SubGD iter. 233/499: loss=840.3875133726258, w0=73.31100000000009, w1=14.704225765405852\n",
      "SubGD iter. 234/499: loss=840.3909655659611, w0=73.30400000000009, w1=14.712042625047856\n",
      "SubGD iter. 235/499: loss=840.3981672927413, w0=73.30400000000009, w1=14.707437378058543\n",
      "SubGD iter. 236/499: loss=840.3921077785035, w0=73.30400000000009, w1=14.702832131069231\n",
      "SubGD iter. 237/499: loss=840.3876370251626, w0=73.31100000000009, w1=14.703758666079379\n",
      "SubGD iter. 238/499: loss=840.3920087802107, w0=73.30400000000009, w1=14.711575525721383\n",
      "SubGD iter. 239/499: loss=840.3975526905222, w0=73.30400000000009, w1=14.70697027873207\n",
      "SubGD iter. 240/499: loss=840.391493176284, w0=73.30400000000009, w1=14.702365031742758\n",
      "SubGD iter. 241/499: loss=840.3877606776996, w0=73.31100000000009, w1=14.703291566752906\n",
      "SubGD iter. 242/499: loss=840.3930519944604, w0=73.30400000000009, w1=14.71110842639491\n",
      "SubGD iter. 243/499: loss=840.3969380883029, w0=73.30400000000009, w1=14.706503179405598\n",
      "SubGD iter. 244/499: loss=840.3908785740651, w0=73.30400000000009, w1=14.701897932416285\n",
      "SubGD iter. 245/499: loss=840.3878843302365, w0=73.31100000000009, w1=14.702824467426433\n",
      "SubGD iter. 246/499: loss=840.39409520871, w0=73.30400000000009, w1=14.710641327068437\n",
      "SubGD iter. 247/499: loss=840.3963234860837, w0=73.30400000000009, w1=14.706036080079125\n",
      "SubGD iter. 248/499: loss=840.390263971846, w0=73.30400000000009, w1=14.701430833089812\n",
      "SubGD iter. 249/499: loss=840.3880079827734, w0=73.31100000000009, w1=14.70235736809996\n",
      "SubGD iter. 250/499: loss=840.3951384229598, w0=73.30400000000009, w1=14.710174227741964\n",
      "SubGD iter. 251/499: loss=840.3957088838647, w0=73.30400000000009, w1=14.705568980752652\n",
      "SubGD iter. 252/499: loss=840.3896493696268, w0=73.30400000000009, w1=14.70096373376334\n",
      "SubGD iter. 253/499: loss=840.3887927297388, w0=73.30400000000009, w1=14.714312375404804\n",
      "SubGD iter. 254/499: loss=840.4011537958834, w0=73.30400000000009, w1=14.709707128415491\n",
      "SubGD iter. 255/499: loss=840.3950942816456, w0=73.30400000000009, w1=14.70510188142618\n",
      "SubGD iter. 256/499: loss=840.3890347674076, w0=73.30400000000009, w1=14.700496634436867\n",
      "SubGD iter. 257/499: loss=840.3905741987446, w0=73.30400000000009, w1=14.713845276078331\n",
      "SubGD iter. 258/499: loss=840.4005391936641, w0=73.30400000000009, w1=14.709240029089019\n",
      "SubGD iter. 259/499: loss=840.3944796794265, w0=73.30400000000009, w1=14.704634782099706\n",
      "SubGD iter. 260/499: loss=840.3884201651886, w0=73.30400000000009, w1=14.700029535110394\n",
      "SubGD iter. 261/499: loss=840.3923556677503, w0=73.30400000000009, w1=14.713378176751858\n",
      "SubGD iter. 262/499: loss=840.3999245914451, w0=73.30400000000009, w1=14.708772929762546\n",
      "SubGD iter. 263/499: loss=840.3938650772072, w0=73.30400000000009, w1=14.704167682773233\n",
      "SubGD iter. 264/499: loss=840.3878055629694, w0=73.30400000000009, w1=14.699562435783921\n",
      "SubGD iter. 265/499: loss=840.3941371367562, w0=73.30400000000009, w1=14.712911077425385\n",
      "SubGD iter. 266/499: loss=840.399309989226, w0=73.30400000000009, w1=14.708305830436073\n",
      "SubGD iter. 267/499: loss=840.3932504749881, w0=73.30400000000009, w1=14.70370058344676\n",
      "SubGD iter. 268/499: loss=840.3874071247249, w0=73.31100000000009, w1=14.704627118456909\n",
      "SubGD iter. 269/499: loss=840.3900691886847, w0=73.30400000000009, w1=14.712443978098912\n",
      "SubGD iter. 270/499: loss=840.3986953870069, w0=73.30400000000009, w1=14.7078387311096\n",
      "SubGD iter. 271/499: loss=840.3926358727692, w0=73.30400000000009, w1=14.703233484120288\n",
      "SubGD iter. 272/499: loss=840.3875307772618, w0=73.31100000000009, w1=14.704160019130436\n",
      "SubGD iter. 273/499: loss=840.3911124029346, w0=73.30400000000009, w1=14.71197687877244\n",
      "SubGD iter. 274/499: loss=840.3980807847879, w0=73.30400000000009, w1=14.707371631783127\n",
      "SubGD iter. 275/499: loss=840.3920212705499, w0=73.30400000000009, w1=14.702766384793815\n",
      "SubGD iter. 276/499: loss=840.3876544297987, w0=73.31100000000009, w1=14.703692919803963\n",
      "SubGD iter. 277/499: loss=840.3921556171842, w0=73.30400000000009, w1=14.711509779445967\n",
      "SubGD iter. 278/499: loss=840.3974661825687, w0=73.30400000000009, w1=14.706904532456655\n",
      "SubGD iter. 279/499: loss=840.3914066683308, w0=73.30400000000009, w1=14.702299285467342\n",
      "SubGD iter. 280/499: loss=840.3877780823357, w0=73.31100000000009, w1=14.70322582047749\n",
      "SubGD iter. 281/499: loss=840.3931988314339, w0=73.30400000000009, w1=14.711042680119494\n",
      "SubGD iter. 282/499: loss=840.3968515803496, w0=73.30400000000009, w1=14.706437433130182\n",
      "SubGD iter. 283/499: loss=840.3907920661115, w0=73.30400000000009, w1=14.70183218614087\n",
      "SubGD iter. 284/499: loss=840.3879017348727, w0=73.31100000000009, w1=14.702758721151017\n",
      "SubGD iter. 285/499: loss=840.3942420456835, w0=73.30400000000009, w1=14.710575580793021\n",
      "SubGD iter. 286/499: loss=840.3962369781304, w0=73.30400000000009, w1=14.705970333803709\n",
      "SubGD iter. 287/499: loss=840.3901774638925, w0=73.30400000000009, w1=14.701365086814397\n",
      "SubGD iter. 288/499: loss=840.3880253874095, w0=73.31100000000009, w1=14.702291621824545\n",
      "SubGD iter. 289/499: loss=840.3952852599331, w0=73.30400000000009, w1=14.710108481466548\n",
      "SubGD iter. 290/499: loss=840.3956223759113, w0=73.30400000000009, w1=14.705503234477236\n",
      "SubGD iter. 291/499: loss=840.3895628616733, w0=73.30400000000009, w1=14.700897987487924\n",
      "SubGD iter. 292/499: loss=840.3890434793016, w0=73.30400000000009, w1=14.714246629129388\n",
      "SubGD iter. 293/499: loss=840.40106728793, w0=73.30400000000009, w1=14.709641382140076\n",
      "SubGD iter. 294/499: loss=840.3950077736922, w0=73.30400000000009, w1=14.705036135150763\n",
      "SubGD iter. 295/499: loss=840.3889482594543, w0=73.30400000000009, w1=14.700430888161451\n",
      "SubGD iter. 296/499: loss=840.3908249483075, w0=73.30400000000009, w1=14.713779529802915\n",
      "SubGD iter. 297/499: loss=840.400452685711, w0=73.30400000000009, w1=14.709174282813603\n",
      "SubGD iter. 298/499: loss=840.394393171473, w0=73.30400000000009, w1=14.70456903582429\n",
      "SubGD iter. 299/499: loss=840.3883336572351, w0=73.30400000000009, w1=14.699963788834978\n",
      "SubGD iter. 300/499: loss=840.3926064173131, w0=73.30400000000009, w1=14.713312430476442\n",
      "SubGD iter. 301/499: loss=840.3998380834919, w0=73.30400000000009, w1=14.70870718348713\n",
      "SubGD iter. 302/499: loss=840.393778569254, w0=73.30400000000009, w1=14.704101936497818\n",
      "SubGD iter. 303/499: loss=840.387719055016, w0=73.30400000000009, w1=14.699496689508505\n",
      "SubGD iter. 304/499: loss=840.3943878863189, w0=73.30400000000009, w1=14.71284533114997\n",
      "SubGD iter. 305/499: loss=840.3992234812727, w0=73.30400000000009, w1=14.708240084160657\n",
      "SubGD iter. 306/499: loss=840.3931639670348, w0=73.30400000000009, w1=14.703634837171345\n",
      "SubGD iter. 307/499: loss=840.3874245293609, w0=73.31100000000009, w1=14.704561372181493\n",
      "SubGD iter. 308/499: loss=840.3902160256582, w0=73.30400000000009, w1=14.712378231823497\n",
      "SubGD iter. 309/499: loss=840.3986088790535, w0=73.30400000000009, w1=14.707772984834184\n",
      "SubGD iter. 310/499: loss=840.3925493648157, w0=73.30400000000009, w1=14.703167737844872\n",
      "SubGD iter. 311/499: loss=840.3875481818977, w0=73.31100000000009, w1=14.70409427285502\n",
      "SubGD iter. 312/499: loss=840.3912592399079, w0=73.30400000000009, w1=14.711911132497024\n",
      "SubGD iter. 313/499: loss=840.3979942768344, w0=73.30400000000009, w1=14.707305885507711\n",
      "SubGD iter. 314/499: loss=840.3919347625965, w0=73.30400000000009, w1=14.7027006385184\n",
      "SubGD iter. 315/499: loss=840.3876718344346, w0=73.31100000000009, w1=14.703627173528547\n",
      "SubGD iter. 316/499: loss=840.3923024541575, w0=73.30400000000009, w1=14.711444033170551\n",
      "SubGD iter. 317/499: loss=840.3973796746153, w0=73.30400000000009, w1=14.706838786181239\n",
      "SubGD iter. 318/499: loss=840.3913201603773, w0=73.30400000000009, w1=14.702233539191926\n",
      "SubGD iter. 319/499: loss=840.3877954869715, w0=73.31100000000009, w1=14.703160074202074\n",
      "SubGD iter. 320/499: loss=840.3933456684072, w0=73.30400000000009, w1=14.710976933844078\n",
      "SubGD iter. 321/499: loss=840.3967650723962, w0=73.30400000000009, w1=14.706371686854766\n",
      "SubGD iter. 322/499: loss=840.3907055581583, w0=73.30400000000009, w1=14.701766439865454\n",
      "SubGD iter. 323/499: loss=840.3879191395085, w0=73.31100000000009, w1=14.702692974875601\n",
      "SubGD iter. 324/499: loss=840.3943888826568, w0=73.30400000000009, w1=14.710509834517605\n",
      "SubGD iter. 325/499: loss=840.3961504701772, w0=73.30400000000009, w1=14.705904587528293\n",
      "SubGD iter. 326/499: loss=840.3900909559392, w0=73.30400000000009, w1=14.70129934053898\n",
      "SubGD iter. 327/499: loss=840.3880427920453, w0=73.31100000000009, w1=14.702225875549129\n",
      "SubGD iter. 328/499: loss=840.3954320969066, w0=73.30400000000009, w1=14.710042735191132\n",
      "SubGD iter. 329/499: loss=840.395535867958, w0=73.30400000000009, w1=14.70543748820182\n",
      "SubGD iter. 330/499: loss=840.38947635372, w0=73.30400000000009, w1=14.700832241212508\n",
      "SubGD iter. 331/499: loss=840.3892942288644, w0=73.30400000000009, w1=14.714180882853972\n",
      "SubGD iter. 332/499: loss=840.4009807799766, w0=73.30400000000009, w1=14.70957563586466\n",
      "SubGD iter. 333/499: loss=840.3949212657387, w0=73.30400000000009, w1=14.704970388875347\n",
      "SubGD iter. 334/499: loss=840.3888617515008, w0=73.30400000000009, w1=14.700365141886035\n",
      "SubGD iter. 335/499: loss=840.3910756978702, w0=73.30400000000009, w1=14.7137137835275\n",
      "SubGD iter. 336/499: loss=840.4003661777574, w0=73.30400000000009, w1=14.709108536538187\n",
      "SubGD iter. 337/499: loss=840.3943066635196, w0=73.30400000000009, w1=14.704503289548875\n",
      "SubGD iter. 338/499: loss=840.3882471492817, w0=73.30400000000009, w1=14.699898042559562\n",
      "SubGD iter. 339/499: loss=840.392857166876, w0=73.30400000000009, w1=14.713246684201026\n",
      "SubGD iter. 340/499: loss=840.3997515755384, w0=73.30400000000009, w1=14.708641437211714\n",
      "SubGD iter. 341/499: loss=840.3936920613005, w0=73.30400000000009, w1=14.704036190222402\n",
      "SubGD iter. 342/499: loss=840.3876325470626, w0=73.30400000000009, w1=14.69943094323309\n",
      "SubGD iter. 343/499: loss=840.3946386358815, w0=73.30400000000009, w1=14.712779584874554\n",
      "SubGD iter. 344/499: loss=840.3991369733193, w0=73.30400000000009, w1=14.708174337885241\n",
      "SubGD iter. 345/499: loss=840.3930774590813, w0=73.30400000000009, w1=14.703569090895929\n",
      "SubGD iter. 346/499: loss=840.3874419339968, w0=73.31100000000009, w1=14.704495625906077\n",
      "SubGD iter. 347/499: loss=840.3903628626315, w0=73.30400000000009, w1=14.71231248554808\n",
      "SubGD iter. 348/499: loss=840.3985223711002, w0=73.30400000000009, w1=14.707707238558768\n",
      "SubGD iter. 349/499: loss=840.3924628568622, w0=73.30400000000009, w1=14.703101991569456\n",
      "SubGD iter. 350/499: loss=840.3875655865337, w0=73.31100000000009, w1=14.704028526579604\n",
      "SubGD iter. 351/499: loss=840.3914060768814, w0=73.30400000000009, w1=14.711845386221608\n",
      "SubGD iter. 352/499: loss=840.397907768881, w0=73.30400000000009, w1=14.707240139232296\n",
      "SubGD iter. 353/499: loss=840.3918482546432, w0=73.30400000000009, w1=14.702634892242983\n",
      "SubGD iter. 354/499: loss=840.3876892390708, w0=73.31100000000009, w1=14.703561427253131\n",
      "SubGD iter. 355/499: loss=840.3924492911309, w0=73.30400000000009, w1=14.711378286895135\n",
      "SubGD iter. 356/499: loss=840.3972931666617, w0=73.30400000000009, w1=14.706773039905823\n",
      "SubGD iter. 357/499: loss=840.3912336524239, w0=73.30400000000009, w1=14.70216779291651\n",
      "SubGD iter. 358/499: loss=840.3878128916076, w0=73.31100000000009, w1=14.703094327926658\n",
      "SubGD iter. 359/499: loss=840.3934925053807, w0=73.30400000000009, w1=14.710911187568662\n",
      "SubGD iter. 360/499: loss=840.3966785644427, w0=73.30400000000009, w1=14.70630594057935\n",
      "SubGD iter. 361/499: loss=840.3906190502048, w0=73.30400000000009, w1=14.701700693590038\n",
      "SubGD iter. 362/499: loss=840.3879365441445, w0=73.31100000000009, w1=14.702627228600186\n",
      "SubGD iter. 363/499: loss=840.3945357196302, w0=73.30400000000009, w1=14.71044408824219\n",
      "SubGD iter. 364/499: loss=840.3960639622235, w0=73.30400000000009, w1=14.705838841252877\n",
      "SubGD iter. 365/499: loss=840.3900044479858, w0=73.30400000000009, w1=14.701233594263565\n",
      "SubGD iter. 366/499: loss=840.3880601966813, w0=73.31100000000009, w1=14.702160129273713\n",
      "SubGD iter. 367/499: loss=840.39557893388, w0=73.30400000000009, w1=14.709976988915717\n",
      "SubGD iter. 368/499: loss=840.3954493600045, w0=73.30400000000009, w1=14.705371741926404\n",
      "SubGD iter. 369/499: loss=840.3893898457666, w0=73.30400000000009, w1=14.700766494937092\n",
      "SubGD iter. 370/499: loss=840.3895449784272, w0=73.30400000000009, w1=14.714115136578556\n",
      "SubGD iter. 371/499: loss=840.4008942720232, w0=73.30400000000009, w1=14.709509889589244\n",
      "SubGD iter. 372/499: loss=840.3948347577854, w0=73.30400000000009, w1=14.704904642599931\n",
      "SubGD iter. 373/499: loss=840.3887752435473, w0=73.30400000000009, w1=14.70029939561062\n",
      "SubGD iter. 374/499: loss=840.3913264474329, w0=73.30400000000009, w1=14.713648037252083\n",
      "SubGD iter. 375/499: loss=840.4002796698041, w0=73.30400000000009, w1=14.709042790262771\n",
      "SubGD iter. 376/499: loss=840.3942201555661, w0=73.30400000000009, w1=14.704437543273459\n",
      "SubGD iter. 377/499: loss=840.3881606413285, w0=73.30400000000009, w1=14.699832296284146\n",
      "SubGD iter. 378/499: loss=840.3931079164387, w0=73.30400000000009, w1=14.71318093792561\n",
      "SubGD iter. 379/499: loss=840.3996650675849, w0=73.30400000000009, w1=14.708575690936298\n",
      "SubGD iter. 380/499: loss=840.3936055533471, w0=73.30400000000009, w1=14.703970443946986\n",
      "SubGD iter. 381/499: loss=840.3875460391092, w0=73.30400000000009, w1=14.699365196957674\n",
      "SubGD iter. 382/499: loss=840.3948893854443, w0=73.30400000000009, w1=14.712713838599138\n",
      "SubGD iter. 383/499: loss=840.3990504653658, w0=73.30400000000009, w1=14.708108591609825\n",
      "SubGD iter. 384/499: loss=840.3929909511281, w0=73.30400000000009, w1=14.703503344620513\n",
      "SubGD iter. 385/499: loss=840.3874593386328, w0=73.31100000000009, w1=14.704429879630661\n",
      "SubGD iter. 386/499: loss=840.390509699605, w0=73.30400000000009, w1=14.712246739272665\n",
      "SubGD iter. 387/499: loss=840.3984358631467, w0=73.30400000000009, w1=14.707641492283352\n",
      "SubGD iter. 388/499: loss=840.3923763489088, w0=73.30400000000009, w1=14.70303624529404\n",
      "SubGD iter. 389/499: loss=840.3875829911699, w0=73.31100000000009, w1=14.703962780304188\n",
      "SubGD iter. 390/499: loss=840.3915529138546, w0=73.30400000000009, w1=14.711779639946192\n",
      "SubGD iter. 391/499: loss=840.3978212609275, w0=73.30400000000009, w1=14.70717439295688\n",
      "SubGD iter. 392/499: loss=840.3917617466898, w0=73.30400000000009, w1=14.702569145967567\n",
      "SubGD iter. 393/499: loss=840.3877066437067, w0=73.31100000000009, w1=14.703495680977715\n",
      "SubGD iter. 394/499: loss=840.3925961281043, w0=73.30400000000009, w1=14.71131254061972\n",
      "SubGD iter. 395/499: loss=840.3972066587085, w0=73.30400000000009, w1=14.706707293630407\n",
      "SubGD iter. 396/499: loss=840.3911471444706, w0=73.30400000000009, w1=14.702102046641095\n",
      "SubGD iter. 397/499: loss=840.3878302962436, w0=73.31100000000009, w1=14.703028581651242\n",
      "SubGD iter. 398/499: loss=840.3936393423539, w0=73.30400000000009, w1=14.710845441293246\n",
      "SubGD iter. 399/499: loss=840.3965920564895, w0=73.30400000000009, w1=14.706240194303934\n",
      "SubGD iter. 400/499: loss=840.3905325422515, w0=73.30400000000009, w1=14.701634947314622\n",
      "SubGD iter. 401/499: loss=840.3879539487805, w0=73.31100000000009, w1=14.70256148232477\n",
      "SubGD iter. 402/499: loss=840.3946825566037, w0=73.30400000000009, w1=14.710378341966774\n",
      "SubGD iter. 403/499: loss=840.3959774542702, w0=73.30400000000009, w1=14.705773094977461\n",
      "SubGD iter. 404/499: loss=840.3899179400323, w0=73.30400000000009, w1=14.701167847988149\n",
      "SubGD iter. 405/499: loss=840.3880776013173, w0=73.31100000000009, w1=14.702094382998297\n",
      "SubGD iter. 406/499: loss=840.3957257708535, w0=73.30400000000009, w1=14.7099112426403\n",
      "SubGD iter. 407/499: loss=840.3953628520511, w0=73.30400000000009, w1=14.705305995650988\n",
      "SubGD iter. 408/499: loss=840.3893033378131, w0=73.30400000000009, w1=14.700700748661676\n",
      "SubGD iter. 409/499: loss=840.38979572799, w0=73.30400000000009, w1=14.71404939030314\n",
      "SubGD iter. 410/499: loss=840.4008077640698, w0=73.30400000000009, w1=14.709444143313828\n",
      "SubGD iter. 411/499: loss=840.394748249832, w0=73.30400000000009, w1=14.704838896324516\n",
      "SubGD iter. 412/499: loss=840.3886887355941, w0=73.30400000000009, w1=14.700233649335203\n",
      "SubGD iter. 413/499: loss=840.3915771969957, w0=73.30400000000009, w1=14.713582290976667\n",
      "SubGD iter. 414/499: loss=840.4001931618507, w0=73.30400000000009, w1=14.708977043987355\n",
      "SubGD iter. 415/499: loss=840.3941336476128, w0=73.30400000000009, w1=14.704371796998043\n",
      "SubGD iter. 416/499: loss=840.388074133375, w0=73.30400000000009, w1=14.69976655000873\n",
      "SubGD iter. 417/499: loss=840.3933586660014, w0=73.30400000000009, w1=14.713115191650195\n",
      "SubGD iter. 418/499: loss=840.3995785596317, w0=73.30400000000009, w1=14.708509944660882\n",
      "SubGD iter. 419/499: loss=840.3935190453938, w0=73.30400000000009, w1=14.70390469767157\n",
      "SubGD iter. 420/499: loss=840.3874595311559, w0=73.30400000000009, w1=14.699299450682258\n",
      "SubGD iter. 421/499: loss=840.3951401350072, w0=73.30400000000009, w1=14.712648092323722\n",
      "SubGD iter. 422/499: loss=840.3989639574124, w0=73.30400000000009, w1=14.70804284533441\n",
      "SubGD iter. 423/499: loss=840.3929044431745, w0=73.30400000000009, w1=14.703437598345097\n",
      "SubGD iter. 424/499: loss=840.3874767432687, w0=73.31100000000009, w1=14.704364133355245\n",
      "SubGD iter. 425/499: loss=840.3906565365785, w0=73.30400000000009, w1=14.712180992997249\n",
      "SubGD iter. 426/499: loss=840.3983493551932, w0=73.30400000000009, w1=14.707575746007937\n",
      "SubGD iter. 427/499: loss=840.3922898409554, w0=73.30400000000009, w1=14.702970499018624\n",
      "SubGD iter. 428/499: loss=840.3876003958057, w0=73.31100000000009, w1=14.703897034028772\n",
      "SubGD iter. 429/499: loss=840.3916997508281, w0=73.30400000000009, w1=14.711713893670776\n",
      "SubGD iter. 430/499: loss=840.3977347529742, w0=73.30400000000009, w1=14.707108646681464\n",
      "SubGD iter. 431/499: loss=840.3916752387363, w0=73.30400000000009, w1=14.702503399692151\n",
      "SubGD iter. 432/499: loss=840.3877240483428, w0=73.31100000000009, w1=14.7034299347023\n",
      "SubGD iter. 433/499: loss=840.3927429650778, w0=73.30400000000009, w1=14.711246794344303\n",
      "SubGD iter. 434/499: loss=840.3971201507551, w0=73.30400000000009, w1=14.706641547354991\n",
      "SubGD iter. 435/499: loss=840.3910606365172, w0=73.30400000000009, w1=14.702036300365679\n",
      "SubGD iter. 436/499: loss=840.3878477008795, w0=73.31100000000009, w1=14.702962835375827\n",
      "SubGD iter. 437/499: loss=840.3937861793274, w0=73.30400000000009, w1=14.71077969501783\n",
      "SubGD iter. 438/499: loss=840.396505548536, w0=73.30400000000009, w1=14.706174448028518\n",
      "SubGD iter. 439/499: loss=840.3904460342981, w0=73.30400000000009, w1=14.701569201039206\n",
      "SubGD iter. 440/499: loss=840.3879713534163, w0=73.31100000000009, w1=14.702495736049354\n",
      "SubGD iter. 441/499: loss=840.3948293935772, w0=73.30400000000009, w1=14.710312595691358\n",
      "SubGD iter. 442/499: loss=840.3958909463167, w0=73.30400000000009, w1=14.705707348702045\n",
      "SubGD iter. 443/499: loss=840.389831432079, w0=73.30400000000009, w1=14.701102101712733\n",
      "SubGD iter. 444/499: loss=840.388265008547, w0=73.30400000000009, w1=14.714450743354197\n",
      "SubGD iter. 445/499: loss=840.4013358583356, w0=73.30400000000009, w1=14.709845496364885\n",
      "SubGD iter. 446/499: loss=840.3952763440976, w0=73.30400000000009, w1=14.705240249375573\n",
      "SubGD iter. 447/499: loss=840.3892168298598, w0=73.30400000000009, w1=14.70063500238626\n",
      "SubGD iter. 448/499: loss=840.3900464775527, w0=73.30400000000009, w1=14.713983644027724\n",
      "SubGD iter. 449/499: loss=840.4007212561164, w0=73.30400000000009, w1=14.709378397038412\n",
      "SubGD iter. 450/499: loss=840.3946617418785, w0=73.30400000000009, w1=14.7047731500491\n",
      "SubGD iter. 451/499: loss=840.3886022276406, w0=73.30400000000009, w1=14.700167903059787\n",
      "SubGD iter. 452/499: loss=840.3918279465586, w0=73.30400000000009, w1=14.713516544701251\n",
      "SubGD iter. 453/499: loss=840.4001066538973, w0=73.30400000000009, w1=14.70891129771194\n",
      "SubGD iter. 454/499: loss=840.3940471396594, w0=73.30400000000009, w1=14.704306050722627\n",
      "SubGD iter. 455/499: loss=840.3879876254216, w0=73.30400000000009, w1=14.699700803733315\n",
      "SubGD iter. 456/499: loss=840.3936094155642, w0=73.30400000000009, w1=14.713049445374779\n",
      "SubGD iter. 457/499: loss=840.3994920516782, w0=73.30400000000009, w1=14.708444198385466\n",
      "SubGD iter. 458/499: loss=840.3934325374403, w0=73.30400000000009, w1=14.703838951396154\n",
      "SubGD iter. 459/499: loss=840.3873730232024, w0=73.30400000000009, w1=14.699233704406842\n",
      "SubGD iter. 460/499: loss=840.39539088457, w0=73.30400000000009, w1=14.712582346048306\n",
      "SubGD iter. 461/499: loss=840.3988774494591, w0=73.30400000000009, w1=14.707977099058994\n",
      "SubGD iter. 462/499: loss=840.3928179352212, w0=73.30400000000009, w1=14.703371852069681\n",
      "SubGD iter. 463/499: loss=840.3874941479048, w0=73.31100000000009, w1=14.70429838707983\n",
      "SubGD iter. 464/499: loss=840.3908033735518, w0=73.30400000000009, w1=14.712115246721833\n",
      "SubGD iter. 465/499: loss=840.3982628472401, w0=73.30400000000009, w1=14.70750999973252\n",
      "SubGD iter. 466/499: loss=840.392203333002, w0=73.30400000000009, w1=14.702904752743208\n",
      "SubGD iter. 467/499: loss=840.3876178004416, w0=73.31100000000009, w1=14.703831287753356\n",
      "SubGD iter. 468/499: loss=840.3918465878014, w0=73.30400000000009, w1=14.71164814739536\n",
      "SubGD iter. 469/499: loss=840.3976482450207, w0=73.30400000000009, w1=14.707042900406048\n",
      "SubGD iter. 470/499: loss=840.3915887307829, w0=73.30400000000009, w1=14.702437653416736\n",
      "SubGD iter. 471/499: loss=840.3877414529786, w0=73.31100000000009, w1=14.703364188426884\n",
      "SubGD iter. 472/499: loss=840.3928898020513, w0=73.30400000000009, w1=14.711181048068887\n",
      "SubGD iter. 473/499: loss=840.3970336428017, w0=73.30400000000009, w1=14.706575801079575\n",
      "SubGD iter. 474/499: loss=840.3909741285638, w0=73.30400000000009, w1=14.701970554090263\n",
      "SubGD iter. 475/499: loss=840.3878651055154, w0=73.31100000000009, w1=14.70289708910041\n",
      "SubGD iter. 476/499: loss=840.3939330163007, w0=73.30400000000009, w1=14.710713948742415\n",
      "SubGD iter. 477/499: loss=840.3964190405826, w0=73.30400000000009, w1=14.706108701753102\n",
      "SubGD iter. 478/499: loss=840.3903595263446, w0=73.30400000000009, w1=14.70150345476379\n",
      "SubGD iter. 479/499: loss=840.3879887580525, w0=73.31100000000009, w1=14.702429989773938\n",
      "SubGD iter. 480/499: loss=840.3949762305506, w0=73.30400000000009, w1=14.710246849415942\n",
      "SubGD iter. 481/499: loss=840.3958044383634, w0=73.30400000000009, w1=14.70564160242663\n",
      "SubGD iter. 482/499: loss=840.3897449241256, w0=73.30400000000009, w1=14.701036355437317\n",
      "SubGD iter. 483/499: loss=840.3885157581099, w0=73.30400000000009, w1=14.714384997078781\n",
      "SubGD iter. 484/499: loss=840.4012493503822, w0=73.30400000000009, w1=14.709779750089469\n",
      "SubGD iter. 485/499: loss=840.3951898361443, w0=73.30400000000009, w1=14.705174503100157\n",
      "SubGD iter. 486/499: loss=840.3891303219064, w0=73.30400000000009, w1=14.700569256110844\n",
      "SubGD iter. 487/499: loss=840.3902972271155, w0=73.30400000000009, w1=14.713917897752308\n",
      "SubGD iter. 488/499: loss=840.400634748163, w0=73.30400000000009, w1=14.709312650762996\n",
      "SubGD iter. 489/499: loss=840.3945752339253, w0=73.30400000000009, w1=14.704707403773684\n",
      "SubGD iter. 490/499: loss=840.3885157196872, w0=73.30400000000009, w1=14.700102156784371\n",
      "SubGD iter. 491/499: loss=840.3920786961212, w0=73.30400000000009, w1=14.713450798425836\n",
      "SubGD iter. 492/499: loss=840.4000201459439, w0=73.30400000000009, w1=14.708845551436523\n",
      "SubGD iter. 493/499: loss=840.393960631706, w0=73.30400000000009, w1=14.704240304447211\n",
      "SubGD iter. 494/499: loss=840.3879011174681, w0=73.30400000000009, w1=14.699635057457899\n",
      "SubGD iter. 495/499: loss=840.3938601651271, w0=73.30400000000009, w1=14.712983699099363\n",
      "SubGD iter. 496/499: loss=840.3994055437248, w0=73.30400000000009, w1=14.70837845211005\n",
      "SubGD iter. 497/499: loss=840.3933460294869, w0=73.30400000000009, w1=14.703773205120738\n",
      "SubGD iter. 498/499: loss=840.3873879000039, w0=73.31100000000009, w1=14.704699740130886\n",
      "SubGD iter. 499/499: loss=840.3899069962754, w0=73.30400000000009, w1=14.71251659977289\n",
      "SubGD: execution time=0.019 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e945007d3914ac4805d533611967d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = np.sum(np.abs(y - tx@w))\n",
    "        gradient = compute_subgradient_mae(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=14726.454491946228, w0=0.7000000000000004, w1=1.6830287163926981e-15\n",
      "SubSGD iter. 1/499: loss=14586.454491946228, w0=1.4000000000000008, w1=3.3660574327853962e-15\n",
      "SubSGD iter. 2/499: loss=14446.454491946228, w0=2.1000000000000014, w1=5.0490861491780946e-15\n",
      "SubSGD iter. 3/499: loss=14306.454491946228, w0=2.8000000000000016, w1=6.7321148655707925e-15\n",
      "SubSGD iter. 4/499: loss=14166.45449194623, w0=3.5000000000000018, w1=8.415143581963491e-15\n",
      "SubSGD iter. 5/499: loss=14026.454491946228, w0=4.200000000000002, w1=1.0098172298356189e-14\n",
      "SubSGD iter. 6/499: loss=13886.454491946228, w0=4.900000000000002, w1=1.1781201014748887e-14\n",
      "SubSGD iter. 7/499: loss=13746.45449194623, w0=5.600000000000002, w1=1.3464229731141585e-14\n",
      "SubSGD iter. 8/499: loss=13606.45449194623, w0=6.3000000000000025, w1=1.5147258447534283e-14\n",
      "SubSGD iter. 9/499: loss=13466.45449194623, w0=7.000000000000003, w1=1.6830287163926982e-14\n",
      "SubSGD iter. 10/499: loss=13326.45449194623, w0=7.700000000000003, w1=1.8513315880319682e-14\n",
      "SubSGD iter. 11/499: loss=13186.454491946228, w0=8.400000000000004, w1=2.019634459671238e-14\n",
      "SubSGD iter. 12/499: loss=13046.454491946228, w0=9.100000000000005, w1=2.187937331310508e-14\n",
      "SubSGD iter. 13/499: loss=12906.45449194623, w0=9.800000000000006, w1=2.356240202949778e-14\n",
      "SubSGD iter. 14/499: loss=12766.454491946228, w0=10.500000000000007, w1=2.524543074589048e-14\n",
      "SubSGD iter. 15/499: loss=12626.454491946228, w0=11.200000000000008, w1=2.692845946228318e-14\n",
      "SubSGD iter. 16/499: loss=12486.45449194623, w0=11.90000000000001, w1=2.861148817867588e-14\n",
      "SubSGD iter. 17/499: loss=12346.454491946228, w0=12.60000000000001, w1=3.029451689506858e-14\n",
      "SubSGD iter. 18/499: loss=12206.454491946228, w0=13.300000000000011, w1=3.197754561146128e-14\n",
      "SubSGD iter. 19/499: loss=12066.454491946228, w0=14.000000000000012, w1=3.366057432785398e-14\n",
      "SubSGD iter. 20/499: loss=11926.454491946228, w0=14.700000000000014, w1=3.534360304424668e-14\n",
      "SubSGD iter. 21/499: loss=11786.454491946228, w0=15.400000000000015, w1=3.7026631760639376e-14\n",
      "SubSGD iter. 22/499: loss=11646.454491946228, w0=16.100000000000016, w1=3.8709660477032076e-14\n",
      "SubSGD iter. 23/499: loss=11506.454491946228, w0=16.800000000000015, w1=4.0392689193424776e-14\n",
      "SubSGD iter. 24/499: loss=11366.454491946228, w0=17.500000000000014, w1=4.2075717909817475e-14\n",
      "SubSGD iter. 25/499: loss=11226.454491946228, w0=18.200000000000014, w1=4.3758746626210175e-14\n",
      "SubSGD iter. 26/499: loss=11086.454491946228, w0=18.900000000000013, w1=4.5441775342602874e-14\n",
      "SubSGD iter. 27/499: loss=10946.454491946228, w0=19.600000000000012, w1=4.7124804058995574e-14\n",
      "SubSGD iter. 28/499: loss=10806.454491946228, w0=20.30000000000001, w1=4.880783277538827e-14\n",
      "SubSGD iter. 29/499: loss=10666.454491946228, w0=21.00000000000001, w1=5.049086149178097e-14\n",
      "SubSGD iter. 30/499: loss=10526.454491946228, w0=21.70000000000001, w1=5.217389020817367e-14\n",
      "SubSGD iter. 31/499: loss=10386.454491946228, w0=22.40000000000001, w1=5.385691892456637e-14\n",
      "SubSGD iter. 32/499: loss=10246.454491946228, w0=23.10000000000001, w1=5.553994764095907e-14\n",
      "SubSGD iter. 33/499: loss=10106.454491946228, w0=23.800000000000008, w1=5.722297635735177e-14\n",
      "SubSGD iter. 34/499: loss=9966.454491946228, w0=24.500000000000007, w1=5.890600507374446e-14\n",
      "SubSGD iter. 35/499: loss=9826.454491946228, w0=25.200000000000006, w1=6.058903379013716e-14\n",
      "SubSGD iter. 36/499: loss=9686.454491946228, w0=25.900000000000006, w1=6.227206250652985e-14\n",
      "SubSGD iter. 37/499: loss=9546.454491946228, w0=26.600000000000005, w1=6.395509122292254e-14\n",
      "SubSGD iter. 38/499: loss=9406.454491946228, w0=27.300000000000004, w1=6.563811993931524e-14\n",
      "SubSGD iter. 39/499: loss=9266.454491946228, w0=28.000000000000004, w1=6.732114865570793e-14\n",
      "SubSGD iter. 40/499: loss=9126.45449194623, w0=28.700000000000003, w1=6.900417737210062e-14\n",
      "SubSGD iter. 41/499: loss=8986.454491946228, w0=29.400000000000002, w1=7.068720608849332e-14\n",
      "SubSGD iter. 42/499: loss=8846.45449194623, w0=30.1, w1=7.237023480488601e-14\n",
      "SubSGD iter. 43/499: loss=8706.45449194623, w0=30.8, w1=7.40532635212787e-14\n",
      "SubSGD iter. 44/499: loss=8566.45449194623, w0=31.5, w1=7.57362922376714e-14\n",
      "SubSGD iter. 45/499: loss=8426.45449194623, w0=32.2, w1=7.741932095406409e-14\n",
      "SubSGD iter. 46/499: loss=8286.45449194623, w0=32.900000000000006, w1=7.910234967045678e-14\n",
      "SubSGD iter. 47/499: loss=8146.454491946229, w0=33.60000000000001, w1=8.078537838684948e-14\n",
      "SubSGD iter. 48/499: loss=8006.454491946228, w0=34.30000000000001, w1=8.246840710324217e-14\n",
      "SubSGD iter. 49/499: loss=7866.454491946228, w0=35.000000000000014, w1=8.415143581963486e-14\n",
      "SubSGD iter. 50/499: loss=7726.454491946226, w0=35.70000000000002, w1=8.583446453602755e-14\n",
      "SubSGD iter. 51/499: loss=7586.454491946227, w0=36.40000000000002, w1=8.751749325242025e-14\n",
      "SubSGD iter. 52/499: loss=7446.454491946226, w0=37.10000000000002, w1=8.920052196881294e-14\n",
      "SubSGD iter. 53/499: loss=7306.454491946224, w0=37.800000000000026, w1=9.088355068520563e-14\n",
      "SubSGD iter. 54/499: loss=7166.454491946224, w0=38.50000000000003, w1=9.256657940159833e-14\n",
      "SubSGD iter. 55/499: loss=7026.454491946224, w0=39.20000000000003, w1=9.424960811799102e-14\n",
      "SubSGD iter. 56/499: loss=6886.454491946224, w0=39.900000000000034, w1=9.593263683438371e-14\n",
      "SubSGD iter. 57/499: loss=6746.454491946222, w0=40.60000000000004, w1=9.761566555077641e-14\n",
      "SubSGD iter. 58/499: loss=6606.454491946222, w0=41.30000000000004, w1=9.92986942671691e-14\n",
      "SubSGD iter. 59/499: loss=6466.4544919462205, w0=42.00000000000004, w1=1.0098172298356179e-13\n",
      "SubSGD iter. 60/499: loss=6326.454491946222, w0=42.700000000000045, w1=1.0266475169995449e-13\n",
      "SubSGD iter. 61/499: loss=6186.454491946221, w0=43.40000000000005, w1=1.0434778041634718e-13\n",
      "SubSGD iter. 62/499: loss=6046.4544919462205, w0=44.10000000000005, w1=1.0603080913273987e-13\n",
      "SubSGD iter. 63/499: loss=5906.45449194622, w0=44.800000000000054, w1=1.0771383784913257e-13\n",
      "SubSGD iter. 64/499: loss=5766.454491946219, w0=45.50000000000006, w1=1.0939686656552526e-13\n",
      "SubSGD iter. 65/499: loss=5626.454491946219, w0=46.20000000000006, w1=1.1107989528191795e-13\n",
      "SubSGD iter. 66/499: loss=5486.454491946217, w0=46.90000000000006, w1=1.1276292399831065e-13\n",
      "SubSGD iter. 67/499: loss=5347.5582916042185, w0=47.59300000000006, w1=0.012822729222840914\n",
      "SubSGD iter. 68/499: loss=5211.006733095646, w0=48.27900000000006, w1=0.038067565076885634\n",
      "SubSGD iter. 69/499: loss=5076.368646884989, w0=48.96500000000006, w1=0.06331240093093035\n",
      "SubSGD iter. 70/499: loss=4943.821025116397, w0=49.63000000000006, w1=0.12140253076845614\n",
      "SubSGD iter. 71/499: loss=4817.424201213635, w0=50.28800000000006, w1=0.19295915708008107\n",
      "SubSGD iter. 72/499: loss=4692.257243851034, w0=50.94600000000006, w1=0.264515783391706\n",
      "SubSGD iter. 73/499: loss=4568.651429724951, w0=51.59000000000006, w1=0.36003710381024756\n",
      "SubSGD iter. 74/499: loss=4448.224392503597, w0=52.22000000000006, w1=0.47488016550951084\n",
      "SubSGD iter. 75/499: loss=4331.057210988867, w0=52.84300000000006, w1=0.6005235649987747\n",
      "SubSGD iter. 76/499: loss=4215.879166545817, w0=53.45900000000006, w1=0.735466325292314\n",
      "SubSGD iter. 77/499: loss=4102.969177162323, w0=54.06800000000006, w1=0.8798253451603704\n",
      "SubSGD iter. 78/499: loss=3992.2250635251867, w0=54.66300000000006, w1=1.0417652853159154\n",
      "SubSGD iter. 79/499: loss=3883.582336605878, w0=55.25800000000006, w1=1.2037052254714604\n",
      "SubSGD iter. 80/499: loss=3775.647382158899, w0=55.83900000000006, w1=1.3822638190738594\n",
      "SubSGD iter. 81/499: loss=3670.6913195125335, w0=56.41300000000006, w1=1.5664626351241269\n",
      "SubSGD iter. 82/499: loss=3568.810467979312, w0=56.95200000000006, w1=1.787159964971011\n",
      "SubSGD iter. 83/499: loss=3472.3432387153216, w0=57.484000000000066, w1=2.01383512121847\n",
      "SubSGD iter. 84/499: loss=3376.7987740125177, w0=58.01600000000007, w1=2.240510277465929\n",
      "SubSGD iter. 85/499: loss=3282.7227005301247, w0=58.51300000000007, w1=2.4977608864129515\n",
      "SubSGD iter. 86/499: loss=3193.240736014806, w0=59.01000000000007, w1=2.755011495359974\n",
      "SubSGD iter. 87/499: loss=3104.6213704263396, w0=59.493000000000066, w1=3.0191142997242326\n",
      "SubSGD iter. 88/499: loss=3018.0387157768932, w0=59.97600000000006, w1=3.283217104088491\n",
      "SubSGD iter. 89/499: loss=2932.1170483974884, w0=60.45200000000006, w1=3.547812933905622\n",
      "SubSGD iter. 90/499: loss=2847.946606167452, w0=60.893000000000065, w1=3.8427091128559843\n",
      "SubSGD iter. 91/499: loss=2768.053488940173, w0=61.320000000000064, w1=4.148442254175183\n",
      "SubSGD iter. 92/499: loss=2689.3793402521887, w0=61.740000000000066, w1=4.458787226613842\n",
      "SubSGD iter. 93/499: loss=2611.4610539899168, w0=62.16000000000007, w1=4.7691321990525015\n",
      "SubSGD iter. 94/499: loss=2533.542767727645, w0=62.58000000000007, w1=5.079477171491161\n",
      "SubSGD iter. 95/499: loss=2456.5439798122916, w0=62.97900000000007, w1=5.401328404320425\n",
      "SubSGD iter. 96/499: loss=2381.9480059927632, w0=63.37100000000007, w1=5.725928703251704\n",
      "SubSGD iter. 97/499: loss=2308.0876493140768, w0=63.74900000000007, w1=6.061744039727746\n",
      "SubSGD iter. 98/499: loss=2235.098420626792, w0=64.12000000000008, w1=6.401747716728321\n",
      "SubSGD iter. 99/499: loss=2162.7431348056743, w0=64.49100000000007, w1=6.741751393728897\n",
      "SubSGD iter. 100/499: loss=2090.6375545806027, w0=64.87600000000008, w1=7.061378131166483\n",
      "SubSGD iter. 101/499: loss=2019.5845075670195, w0=65.24700000000007, w1=7.38752359388077\n",
      "SubSGD iter. 102/499: loss=1949.8668324672722, w0=65.61800000000007, w1=7.713669056595057\n",
      "SubSGD iter. 103/499: loss=1880.2483470148386, w0=65.98200000000007, w1=8.040435506798632\n",
      "SubSGD iter. 104/499: loss=1812.1298841840376, w0=66.34600000000007, w1=8.353859837656556\n",
      "SubSGD iter. 105/499: loss=1746.4006548551508, w0=66.71700000000007, w1=8.653513683656954\n",
      "SubSGD iter. 106/499: loss=1681.9160483895998, w0=67.08100000000007, w1=8.955524223771471\n",
      "SubSGD iter. 107/499: loss=1618.140453250564, w0=67.43800000000007, w1=9.25498501711051\n",
      "SubSGD iter. 108/499: loss=1556.2651523864465, w0=67.78100000000008, w1=9.560846653934\n",
      "SubSGD iter. 109/499: loss=1496.7592255253683, w0=68.11700000000008, w1=9.860337267127163\n",
      "SubSGD iter. 110/499: loss=1439.9601430154758, w0=68.43200000000007, w1=10.156521139455208\n",
      "SubSGD iter. 111/499: loss=1386.6527757932383, w0=68.74700000000007, w1=10.44445347734849\n",
      "SubSGD iter. 112/499: loss=1335.6241282326146, w0=69.03400000000008, w1=10.743406876764546\n",
      "SubSGD iter. 113/499: loss=1287.0324873064683, w0=69.31400000000008, w1=11.038005391074634\n",
      "SubSGD iter. 114/499: loss=1240.9197621286332, w0=69.59400000000008, w1=11.313287847901128\n",
      "SubSGD iter. 115/499: loss=1197.8246319572079, w0=69.86700000000008, w1=11.578413278202849\n",
      "SubSGD iter. 116/499: loss=1156.4473480164443, w0=70.14000000000007, w1=11.84353870850457\n",
      "SubSGD iter. 117/499: loss=1115.519407789417, w0=70.39900000000007, w1=12.104101240231255\n",
      "SubSGD iter. 118/499: loss=1077.1524301779511, w0=70.65100000000007, w1=12.36722983468918\n",
      "SubSGD iter. 119/499: loss=1039.5455769657992, w0=70.90300000000006, w1=12.607410619209126\n",
      "SubSGD iter. 120/499: loss=1005.7298171408189, w0=71.14800000000007, w1=12.829819894660053\n",
      "SubSGD iter. 121/499: loss=975.0141283425196, w0=71.37900000000006, w1=13.051299546685472\n",
      "SubSGD iter. 122/499: loss=947.005951176285, w0=71.59600000000006, w1=13.253978279130127\n",
      "SubSGD iter. 123/499: loss=922.951196549194, w0=71.80600000000005, w1=13.44375255576234\n",
      "SubSGD iter. 124/499: loss=901.4425616297469, w0=71.98100000000005, w1=13.60001256733913\n",
      "SubSGD iter. 125/499: loss=888.2351261015862, w0=72.12100000000005, w1=13.709638751573955\n",
      "SubSGD iter. 126/499: loss=879.2254392589161, w0=72.25400000000005, w1=13.823710297553665\n",
      "SubSGD iter. 127/499: loss=871.4570898839752, w0=72.35900000000005, w1=13.928950177753492\n",
      "SubSGD iter. 128/499: loss=865.2751251926044, w0=72.45700000000005, w1=14.033063640618643\n",
      "SubSGD iter. 129/499: loss=860.085960553727, w0=72.53400000000005, w1=14.118590076651575\n",
      "SubSGD iter. 130/499: loss=856.3020259078714, w0=72.61100000000005, w1=14.204116512684507\n",
      "SubSGD iter. 131/499: loss=852.9488952284264, w0=72.66700000000004, w1=14.262362322468729\n",
      "SubSGD iter. 132/499: loss=851.110855996505, w0=72.71600000000005, w1=14.31250818978189\n",
      "SubSGD iter. 133/499: loss=849.7063965654795, w0=72.76500000000006, w1=14.362654057095053\n",
      "SubSGD iter. 134/499: loss=848.301937134454, w0=72.81400000000006, w1=14.412799924408215\n",
      "SubSGD iter. 135/499: loss=846.8974777034284, w0=72.86300000000007, w1=14.462945791721378\n",
      "SubSGD iter. 136/499: loss=845.5295902476282, w0=72.91900000000007, w1=14.500669552403224\n",
      "SubSGD iter. 137/499: loss=844.38790536032, w0=72.96100000000007, w1=14.528246426173608\n",
      "SubSGD iter. 138/499: loss=843.6670445700101, w0=73.01000000000008, w1=14.543000570721267\n",
      "SubSGD iter. 139/499: loss=842.9928828207533, w0=73.04500000000007, w1=14.568377913364845\n",
      "SubSGD iter. 140/499: loss=842.5634122278454, w0=73.07300000000008, w1=14.586058146365021\n",
      "SubSGD iter. 141/499: loss=842.2501006167196, w0=73.10100000000008, w1=14.603738379365197\n",
      "SubSGD iter. 142/499: loss=841.9367890055937, w0=73.12900000000009, w1=14.621418612365373\n",
      "SubSGD iter. 143/499: loss=841.6292467988933, w0=73.16400000000009, w1=14.626276116142824\n",
      "SubSGD iter. 144/499: loss=841.3963068271992, w0=73.18500000000009, w1=14.637490968842984\n",
      "SubSGD iter. 145/499: loss=841.2343717068886, w0=73.20600000000009, w1=14.648705821543144\n",
      "SubSGD iter. 146/499: loss=841.0724365865782, w0=73.22700000000009, w1=14.659920674243304\n",
      "SubSGD iter. 147/499: loss=840.910501466268, w0=73.24800000000009, w1=14.671135526943464\n",
      "SubSGD iter. 148/499: loss=840.7485663459574, w0=73.26900000000009, w1=14.682350379643625\n",
      "SubSGD iter. 149/499: loss=840.5866312256471, w0=73.29000000000009, w1=14.693565232343785\n",
      "SubSGD iter. 150/499: loss=840.4334388338245, w0=73.30400000000009, w1=14.703897822273008\n",
      "SubSGD iter. 151/499: loss=840.3874504846104, w0=73.30400000000009, w1=14.699292575283696\n",
      "SubSGD iter. 152/499: loss=840.3951663570733, w0=73.30400000000009, w1=14.71264121692516\n",
      "SubSGD iter. 153/499: loss=840.3989549108671, w0=73.30400000000009, w1=14.708035969935848\n",
      "SubSGD iter. 154/499: loss=840.3928953966292, w0=73.30400000000009, w1=14.703430722946536\n",
      "SubSGD iter. 155/499: loss=840.3874785633539, w0=73.31100000000009, w1=14.704357257956683\n",
      "SubSGD iter. 156/499: loss=840.3906718920142, w0=73.30400000000009, w1=14.712174117598687\n",
      "SubSGD iter. 157/499: loss=840.3983403086479, w0=73.30400000000009, w1=14.707568870609375\n",
      "SubSGD iter. 158/499: loss=840.39228079441, w0=73.30400000000009, w1=14.702963623620063\n",
      "SubSGD iter. 159/499: loss=840.3876022158906, w0=73.31100000000009, w1=14.70389015863021\n",
      "SubSGD iter. 160/499: loss=840.391715106264, w0=73.30400000000009, w1=14.711707018272214\n",
      "SubSGD iter. 161/499: loss=840.3977257064289, w0=73.30400000000009, w1=14.707101771282902\n",
      "SubSGD iter. 162/499: loss=840.3916661921911, w0=73.30400000000009, w1=14.70249652429359\n",
      "SubSGD iter. 163/499: loss=840.3877258684277, w0=73.31100000000009, w1=14.703423059303738\n",
      "SubSGD iter. 164/499: loss=840.3927583205136, w0=73.30400000000009, w1=14.711239918945742\n",
      "SubSGD iter. 165/499: loss=840.3971111042097, w0=73.30400000000009, w1=14.70663467195643\n",
      "SubSGD iter. 166/499: loss=840.391051589972, w0=73.30400000000009, w1=14.702029424967117\n",
      "SubSGD iter. 167/499: loss=840.3878495209646, w0=73.31100000000009, w1=14.702955959977265\n",
      "SubSGD iter. 168/499: loss=840.3938015347633, w0=73.30400000000009, w1=14.710772819619269\n",
      "SubSGD iter. 169/499: loss=840.3964965019907, w0=73.30400000000009, w1=14.706167572629957\n",
      "SubSGD iter. 170/499: loss=840.3904369877528, w0=73.30400000000009, w1=14.701562325640644\n",
      "SubSGD iter. 171/499: loss=840.3879731735015, w0=73.31100000000009, w1=14.702488860650792\n",
      "SubSGD iter. 172/499: loss=840.3948447490131, w0=73.30400000000009, w1=14.710305720292796\n",
      "SubSGD iter. 173/499: loss=840.3958818997714, w0=73.30400000000009, w1=14.705700473303484\n",
      "SubSGD iter. 174/499: loss=840.3898223855336, w0=73.30400000000009, w1=14.701095226314171\n",
      "SubSGD iter. 175/499: loss=840.3882912306133, w0=73.30400000000009, w1=14.714443867955636\n",
      "SubSGD iter. 176/499: loss=840.4013268117903, w0=73.30400000000009, w1=14.709838620966323\n",
      "SubSGD iter. 177/499: loss=840.3952672975523, w0=73.30400000000009, w1=14.705233373977011\n",
      "SubSGD iter. 178/499: loss=840.3892077833145, w0=73.30400000000009, w1=14.700628126987699\n",
      "SubSGD iter. 179/499: loss=840.3900726996189, w0=73.30400000000009, w1=14.713976768629163\n",
      "SubSGD iter. 180/499: loss=840.4007122095711, w0=73.30400000000009, w1=14.70937152163985\n",
      "SubSGD iter. 181/499: loss=840.3946526953334, w0=73.30400000000009, w1=14.704766274650538\n",
      "SubSGD iter. 182/499: loss=840.3885931810953, w0=73.30400000000009, w1=14.700161027661226\n",
      "SubSGD iter. 183/499: loss=840.3918541686246, w0=73.30400000000009, w1=14.71350966930269\n",
      "SubSGD iter. 184/499: loss=840.4000976073519, w0=73.30400000000009, w1=14.708904422313378\n",
      "SubSGD iter. 185/499: loss=840.394038093114, w0=73.30400000000009, w1=14.704299175324065\n",
      "SubSGD iter. 186/499: loss=840.3879785788763, w0=73.30400000000009, w1=14.699693928334753\n",
      "SubSGD iter. 187/499: loss=840.3936356376304, w0=73.30400000000009, w1=14.713042569976217\n",
      "SubSGD iter. 188/499: loss=840.3994830051329, w0=73.30400000000009, w1=14.708437322986905\n",
      "SubSGD iter. 189/499: loss=840.3934234908949, w0=73.30400000000009, w1=14.703832075997592\n",
      "SubSGD iter. 190/499: loss=840.3873723154529, w0=73.31100000000009, w1=14.70475861100774\n",
      "SubSGD iter. 191/499: loss=840.389775514738, w0=73.30400000000009, w1=14.712575470649744\n",
      "SubSGD iter. 192/499: loss=840.3988684029136, w0=73.30400000000009, w1=14.707970223660432\n",
      "SubSGD iter. 193/499: loss=840.3928088886759, w0=73.30400000000009, w1=14.70336497667112\n",
      "SubSGD iter. 194/499: loss=840.3874959679897, w0=73.31100000000009, w1=14.704291511681268\n",
      "SubSGD iter. 195/499: loss=840.3908187289876, w0=73.30400000000009, w1=14.712108371323271\n",
      "SubSGD iter. 196/499: loss=840.3982538006946, w0=73.30400000000009, w1=14.70750312433396\n",
      "SubSGD iter. 197/499: loss=840.3921942864566, w0=73.30400000000009, w1=14.702897877344647\n",
      "SubSGD iter. 198/499: loss=840.3876196205267, w0=73.31100000000009, w1=14.703824412354795\n",
      "SubSGD iter. 199/499: loss=840.3918619432372, w0=73.30400000000009, w1=14.711641271996799\n",
      "SubSGD iter. 200/499: loss=840.3976391984755, w0=73.30400000000009, w1=14.707036025007486\n",
      "SubSGD iter. 201/499: loss=840.3915796842375, w0=73.30400000000009, w1=14.702430778018174\n",
      "SubSGD iter. 202/499: loss=840.3877432730636, w0=73.31100000000009, w1=14.703357313028322\n",
      "SubSGD iter. 203/499: loss=840.392905157487, w0=73.30400000000009, w1=14.711174172670326\n",
      "SubSGD iter. 204/499: loss=840.3970245962564, w0=73.30400000000009, w1=14.706568925681013\n",
      "SubSGD iter. 205/499: loss=840.3909650820185, w0=73.30400000000009, w1=14.701963678691701\n",
      "SubSGD iter. 206/499: loss=840.3878669256004, w0=73.31100000000009, w1=14.70289021370185\n",
      "SubSGD iter. 207/499: loss=840.3939483717368, w0=73.30400000000009, w1=14.710707073343853\n",
      "SubSGD iter. 208/499: loss=840.3964099940372, w0=73.30400000000009, w1=14.70610182635454\n",
      "SubSGD iter. 209/499: loss=840.3903504797994, w0=73.30400000000009, w1=14.701496579365228\n",
      "SubSGD iter. 210/499: loss=840.3879905781374, w0=73.31100000000009, w1=14.702423114375376\n",
      "SubSGD iter. 211/499: loss=840.3949915859864, w0=73.30400000000009, w1=14.71023997401738\n",
      "SubSGD iter. 212/499: loss=840.395795391818, w0=73.30400000000009, w1=14.705634727028068\n",
      "SubSGD iter. 213/499: loss=840.3897358775803, w0=73.30400000000009, w1=14.701029480038756\n",
      "SubSGD iter. 214/499: loss=840.388541980176, w0=73.30400000000009, w1=14.71437812168022\n",
      "SubSGD iter. 215/499: loss=840.4012403038369, w0=73.30400000000009, w1=14.709772874690907\n",
      "SubSGD iter. 216/499: loss=840.3951807895991, w0=73.30400000000009, w1=14.705167627701595\n",
      "SubSGD iter. 217/499: loss=840.389121275361, w0=73.30400000000009, w1=14.700562380712283\n",
      "SubSGD iter. 218/499: loss=840.3903234491818, w0=73.30400000000009, w1=14.713911022353747\n",
      "SubSGD iter. 219/499: loss=840.4006257016177, w0=73.30400000000009, w1=14.709305775364435\n",
      "SubSGD iter. 220/499: loss=840.3945661873798, w0=73.30400000000009, w1=14.704700528375122\n",
      "SubSGD iter. 221/499: loss=840.3885066731419, w0=73.30400000000009, w1=14.70009528138581\n",
      "SubSGD iter. 222/499: loss=840.3921049181874, w0=73.30400000000009, w1=14.713443923027274\n",
      "SubSGD iter. 223/499: loss=840.4000110993986, w0=73.30400000000009, w1=14.708838676037962\n",
      "SubSGD iter. 224/499: loss=840.3939515851607, w0=73.30400000000009, w1=14.70423342904865\n",
      "SubSGD iter. 225/499: loss=840.3878920709228, w0=73.30400000000009, w1=14.699628182059337\n",
      "SubSGD iter. 226/499: loss=840.3938863871932, w0=73.30400000000009, w1=14.712976823700801\n",
      "SubSGD iter. 227/499: loss=840.3993964971795, w0=73.30400000000009, w1=14.708371576711489\n",
      "SubSGD iter. 228/499: loss=840.3933369829417, w0=73.30400000000009, w1=14.703766329722177\n",
      "SubSGD iter. 229/499: loss=840.387389720089, w0=73.31100000000009, w1=14.704692864732325\n",
      "SubSGD iter. 230/499: loss=840.3899223517112, w0=73.30400000000009, w1=14.712509724374328\n",
      "SubSGD iter. 231/499: loss=840.3987818949603, w0=73.30400000000009, w1=14.707904477385016\n",
      "SubSGD iter. 232/499: loss=840.3927223807224, w0=73.30400000000009, w1=14.703299230395704\n",
      "SubSGD iter. 233/499: loss=840.3875133726258, w0=73.31100000000009, w1=14.704225765405852\n",
      "SubSGD iter. 234/499: loss=840.3909655659611, w0=73.30400000000009, w1=14.712042625047856\n",
      "SubSGD iter. 235/499: loss=840.3981672927413, w0=73.30400000000009, w1=14.707437378058543\n",
      "SubSGD iter. 236/499: loss=840.3921077785035, w0=73.30400000000009, w1=14.702832131069231\n",
      "SubSGD iter. 237/499: loss=840.3876370251626, w0=73.31100000000009, w1=14.703758666079379\n",
      "SubSGD iter. 238/499: loss=840.3920087802107, w0=73.30400000000009, w1=14.711575525721383\n",
      "SubSGD iter. 239/499: loss=840.3975526905222, w0=73.30400000000009, w1=14.70697027873207\n",
      "SubSGD iter. 240/499: loss=840.391493176284, w0=73.30400000000009, w1=14.702365031742758\n",
      "SubSGD iter. 241/499: loss=840.3877606776996, w0=73.31100000000009, w1=14.703291566752906\n",
      "SubSGD iter. 242/499: loss=840.3930519944604, w0=73.30400000000009, w1=14.71110842639491\n",
      "SubSGD iter. 243/499: loss=840.3969380883029, w0=73.30400000000009, w1=14.706503179405598\n",
      "SubSGD iter. 244/499: loss=840.3908785740651, w0=73.30400000000009, w1=14.701897932416285\n",
      "SubSGD iter. 245/499: loss=840.3878843302365, w0=73.31100000000009, w1=14.702824467426433\n",
      "SubSGD iter. 246/499: loss=840.39409520871, w0=73.30400000000009, w1=14.710641327068437\n",
      "SubSGD iter. 247/499: loss=840.3963234860837, w0=73.30400000000009, w1=14.706036080079125\n",
      "SubSGD iter. 248/499: loss=840.390263971846, w0=73.30400000000009, w1=14.701430833089812\n",
      "SubSGD iter. 249/499: loss=840.3880079827734, w0=73.31100000000009, w1=14.70235736809996\n",
      "SubSGD iter. 250/499: loss=840.3951384229598, w0=73.30400000000009, w1=14.710174227741964\n",
      "SubSGD iter. 251/499: loss=840.3957088838647, w0=73.30400000000009, w1=14.705568980752652\n",
      "SubSGD iter. 252/499: loss=840.3896493696268, w0=73.30400000000009, w1=14.70096373376334\n",
      "SubSGD iter. 253/499: loss=840.3887927297388, w0=73.30400000000009, w1=14.714312375404804\n",
      "SubSGD iter. 254/499: loss=840.4011537958834, w0=73.30400000000009, w1=14.709707128415491\n",
      "SubSGD iter. 255/499: loss=840.3950942816456, w0=73.30400000000009, w1=14.70510188142618\n",
      "SubSGD iter. 256/499: loss=840.3890347674076, w0=73.30400000000009, w1=14.700496634436867\n",
      "SubSGD iter. 257/499: loss=840.3905741987446, w0=73.30400000000009, w1=14.713845276078331\n",
      "SubSGD iter. 258/499: loss=840.4005391936641, w0=73.30400000000009, w1=14.709240029089019\n",
      "SubSGD iter. 259/499: loss=840.3944796794265, w0=73.30400000000009, w1=14.704634782099706\n",
      "SubSGD iter. 260/499: loss=840.3884201651886, w0=73.30400000000009, w1=14.700029535110394\n",
      "SubSGD iter. 261/499: loss=840.3923556677503, w0=73.30400000000009, w1=14.713378176751858\n",
      "SubSGD iter. 262/499: loss=840.3999245914451, w0=73.30400000000009, w1=14.708772929762546\n",
      "SubSGD iter. 263/499: loss=840.3938650772072, w0=73.30400000000009, w1=14.704167682773233\n",
      "SubSGD iter. 264/499: loss=840.3878055629694, w0=73.30400000000009, w1=14.699562435783921\n",
      "SubSGD iter. 265/499: loss=840.3941371367562, w0=73.30400000000009, w1=14.712911077425385\n",
      "SubSGD iter. 266/499: loss=840.399309989226, w0=73.30400000000009, w1=14.708305830436073\n",
      "SubSGD iter. 267/499: loss=840.3932504749881, w0=73.30400000000009, w1=14.70370058344676\n",
      "SubSGD iter. 268/499: loss=840.3874071247249, w0=73.31100000000009, w1=14.704627118456909\n",
      "SubSGD iter. 269/499: loss=840.3900691886847, w0=73.30400000000009, w1=14.712443978098912\n",
      "SubSGD iter. 270/499: loss=840.3986953870069, w0=73.30400000000009, w1=14.7078387311096\n",
      "SubSGD iter. 271/499: loss=840.3926358727692, w0=73.30400000000009, w1=14.703233484120288\n",
      "SubSGD iter. 272/499: loss=840.3875307772618, w0=73.31100000000009, w1=14.704160019130436\n",
      "SubSGD iter. 273/499: loss=840.3911124029346, w0=73.30400000000009, w1=14.71197687877244\n",
      "SubSGD iter. 274/499: loss=840.3980807847879, w0=73.30400000000009, w1=14.707371631783127\n",
      "SubSGD iter. 275/499: loss=840.3920212705499, w0=73.30400000000009, w1=14.702766384793815\n",
      "SubSGD iter. 276/499: loss=840.3876544297987, w0=73.31100000000009, w1=14.703692919803963\n",
      "SubSGD iter. 277/499: loss=840.3921556171842, w0=73.30400000000009, w1=14.711509779445967\n",
      "SubSGD iter. 278/499: loss=840.3974661825687, w0=73.30400000000009, w1=14.706904532456655\n",
      "SubSGD iter. 279/499: loss=840.3914066683308, w0=73.30400000000009, w1=14.702299285467342\n",
      "SubSGD iter. 280/499: loss=840.3877780823357, w0=73.31100000000009, w1=14.70322582047749\n",
      "SubSGD iter. 281/499: loss=840.3931988314339, w0=73.30400000000009, w1=14.711042680119494\n",
      "SubSGD iter. 282/499: loss=840.3968515803496, w0=73.30400000000009, w1=14.706437433130182\n",
      "SubSGD iter. 283/499: loss=840.3907920661115, w0=73.30400000000009, w1=14.70183218614087\n",
      "SubSGD iter. 284/499: loss=840.3879017348727, w0=73.31100000000009, w1=14.702758721151017\n",
      "SubSGD iter. 285/499: loss=840.3942420456835, w0=73.30400000000009, w1=14.710575580793021\n",
      "SubSGD iter. 286/499: loss=840.3962369781304, w0=73.30400000000009, w1=14.705970333803709\n",
      "SubSGD iter. 287/499: loss=840.3901774638925, w0=73.30400000000009, w1=14.701365086814397\n",
      "SubSGD iter. 288/499: loss=840.3880253874095, w0=73.31100000000009, w1=14.702291621824545\n",
      "SubSGD iter. 289/499: loss=840.3952852599331, w0=73.30400000000009, w1=14.710108481466548\n",
      "SubSGD iter. 290/499: loss=840.3956223759113, w0=73.30400000000009, w1=14.705503234477236\n",
      "SubSGD iter. 291/499: loss=840.3895628616733, w0=73.30400000000009, w1=14.700897987487924\n",
      "SubSGD iter. 292/499: loss=840.3890434793016, w0=73.30400000000009, w1=14.714246629129388\n",
      "SubSGD iter. 293/499: loss=840.40106728793, w0=73.30400000000009, w1=14.709641382140076\n",
      "SubSGD iter. 294/499: loss=840.3950077736922, w0=73.30400000000009, w1=14.705036135150763\n",
      "SubSGD iter. 295/499: loss=840.3889482594543, w0=73.30400000000009, w1=14.700430888161451\n",
      "SubSGD iter. 296/499: loss=840.3908249483075, w0=73.30400000000009, w1=14.713779529802915\n",
      "SubSGD iter. 297/499: loss=840.400452685711, w0=73.30400000000009, w1=14.709174282813603\n",
      "SubSGD iter. 298/499: loss=840.394393171473, w0=73.30400000000009, w1=14.70456903582429\n",
      "SubSGD iter. 299/499: loss=840.3883336572351, w0=73.30400000000009, w1=14.699963788834978\n",
      "SubSGD iter. 300/499: loss=840.3926064173131, w0=73.30400000000009, w1=14.713312430476442\n",
      "SubSGD iter. 301/499: loss=840.3998380834919, w0=73.30400000000009, w1=14.70870718348713\n",
      "SubSGD iter. 302/499: loss=840.393778569254, w0=73.30400000000009, w1=14.704101936497818\n",
      "SubSGD iter. 303/499: loss=840.387719055016, w0=73.30400000000009, w1=14.699496689508505\n",
      "SubSGD iter. 304/499: loss=840.3943878863189, w0=73.30400000000009, w1=14.71284533114997\n",
      "SubSGD iter. 305/499: loss=840.3992234812727, w0=73.30400000000009, w1=14.708240084160657\n",
      "SubSGD iter. 306/499: loss=840.3931639670348, w0=73.30400000000009, w1=14.703634837171345\n",
      "SubSGD iter. 307/499: loss=840.3874245293609, w0=73.31100000000009, w1=14.704561372181493\n",
      "SubSGD iter. 308/499: loss=840.3902160256582, w0=73.30400000000009, w1=14.712378231823497\n",
      "SubSGD iter. 309/499: loss=840.3986088790535, w0=73.30400000000009, w1=14.707772984834184\n",
      "SubSGD iter. 310/499: loss=840.3925493648157, w0=73.30400000000009, w1=14.703167737844872\n",
      "SubSGD iter. 311/499: loss=840.3875481818977, w0=73.31100000000009, w1=14.70409427285502\n",
      "SubSGD iter. 312/499: loss=840.3912592399079, w0=73.30400000000009, w1=14.711911132497024\n",
      "SubSGD iter. 313/499: loss=840.3979942768344, w0=73.30400000000009, w1=14.707305885507711\n",
      "SubSGD iter. 314/499: loss=840.3919347625965, w0=73.30400000000009, w1=14.7027006385184\n",
      "SubSGD iter. 315/499: loss=840.3876718344346, w0=73.31100000000009, w1=14.703627173528547\n",
      "SubSGD iter. 316/499: loss=840.3923024541575, w0=73.30400000000009, w1=14.711444033170551\n",
      "SubSGD iter. 317/499: loss=840.3973796746153, w0=73.30400000000009, w1=14.706838786181239\n",
      "SubSGD iter. 318/499: loss=840.3913201603773, w0=73.30400000000009, w1=14.702233539191926\n",
      "SubSGD iter. 319/499: loss=840.3877954869715, w0=73.31100000000009, w1=14.703160074202074\n",
      "SubSGD iter. 320/499: loss=840.3933456684072, w0=73.30400000000009, w1=14.710976933844078\n",
      "SubSGD iter. 321/499: loss=840.3967650723962, w0=73.30400000000009, w1=14.706371686854766\n",
      "SubSGD iter. 322/499: loss=840.3907055581583, w0=73.30400000000009, w1=14.701766439865454\n",
      "SubSGD iter. 323/499: loss=840.3879191395085, w0=73.31100000000009, w1=14.702692974875601\n",
      "SubSGD iter. 324/499: loss=840.3943888826568, w0=73.30400000000009, w1=14.710509834517605\n",
      "SubSGD iter. 325/499: loss=840.3961504701772, w0=73.30400000000009, w1=14.705904587528293\n",
      "SubSGD iter. 326/499: loss=840.3900909559392, w0=73.30400000000009, w1=14.70129934053898\n",
      "SubSGD iter. 327/499: loss=840.3880427920453, w0=73.31100000000009, w1=14.702225875549129\n",
      "SubSGD iter. 328/499: loss=840.3954320969066, w0=73.30400000000009, w1=14.710042735191132\n",
      "SubSGD iter. 329/499: loss=840.395535867958, w0=73.30400000000009, w1=14.70543748820182\n",
      "SubSGD iter. 330/499: loss=840.38947635372, w0=73.30400000000009, w1=14.700832241212508\n",
      "SubSGD iter. 331/499: loss=840.3892942288644, w0=73.30400000000009, w1=14.714180882853972\n",
      "SubSGD iter. 332/499: loss=840.4009807799766, w0=73.30400000000009, w1=14.70957563586466\n",
      "SubSGD iter. 333/499: loss=840.3949212657387, w0=73.30400000000009, w1=14.704970388875347\n",
      "SubSGD iter. 334/499: loss=840.3888617515008, w0=73.30400000000009, w1=14.700365141886035\n",
      "SubSGD iter. 335/499: loss=840.3910756978702, w0=73.30400000000009, w1=14.7137137835275\n",
      "SubSGD iter. 336/499: loss=840.4003661777574, w0=73.30400000000009, w1=14.709108536538187\n",
      "SubSGD iter. 337/499: loss=840.3943066635196, w0=73.30400000000009, w1=14.704503289548875\n",
      "SubSGD iter. 338/499: loss=840.3882471492817, w0=73.30400000000009, w1=14.699898042559562\n",
      "SubSGD iter. 339/499: loss=840.392857166876, w0=73.30400000000009, w1=14.713246684201026\n",
      "SubSGD iter. 340/499: loss=840.3997515755384, w0=73.30400000000009, w1=14.708641437211714\n",
      "SubSGD iter. 341/499: loss=840.3936920613005, w0=73.30400000000009, w1=14.704036190222402\n",
      "SubSGD iter. 342/499: loss=840.3876325470626, w0=73.30400000000009, w1=14.69943094323309\n",
      "SubSGD iter. 343/499: loss=840.3946386358815, w0=73.30400000000009, w1=14.712779584874554\n",
      "SubSGD iter. 344/499: loss=840.3991369733193, w0=73.30400000000009, w1=14.708174337885241\n",
      "SubSGD iter. 345/499: loss=840.3930774590813, w0=73.30400000000009, w1=14.703569090895929\n",
      "SubSGD iter. 346/499: loss=840.3874419339968, w0=73.31100000000009, w1=14.704495625906077\n",
      "SubSGD iter. 347/499: loss=840.3903628626315, w0=73.30400000000009, w1=14.71231248554808\n",
      "SubSGD iter. 348/499: loss=840.3985223711002, w0=73.30400000000009, w1=14.707707238558768\n",
      "SubSGD iter. 349/499: loss=840.3924628568622, w0=73.30400000000009, w1=14.703101991569456\n",
      "SubSGD iter. 350/499: loss=840.3875655865337, w0=73.31100000000009, w1=14.704028526579604\n",
      "SubSGD iter. 351/499: loss=840.3914060768814, w0=73.30400000000009, w1=14.711845386221608\n",
      "SubSGD iter. 352/499: loss=840.397907768881, w0=73.30400000000009, w1=14.707240139232296\n",
      "SubSGD iter. 353/499: loss=840.3918482546432, w0=73.30400000000009, w1=14.702634892242983\n",
      "SubSGD iter. 354/499: loss=840.3876892390708, w0=73.31100000000009, w1=14.703561427253131\n",
      "SubSGD iter. 355/499: loss=840.3924492911309, w0=73.30400000000009, w1=14.711378286895135\n",
      "SubSGD iter. 356/499: loss=840.3972931666617, w0=73.30400000000009, w1=14.706773039905823\n",
      "SubSGD iter. 357/499: loss=840.3912336524239, w0=73.30400000000009, w1=14.70216779291651\n",
      "SubSGD iter. 358/499: loss=840.3878128916076, w0=73.31100000000009, w1=14.703094327926658\n",
      "SubSGD iter. 359/499: loss=840.3934925053807, w0=73.30400000000009, w1=14.710911187568662\n",
      "SubSGD iter. 360/499: loss=840.3966785644427, w0=73.30400000000009, w1=14.70630594057935\n",
      "SubSGD iter. 361/499: loss=840.3906190502048, w0=73.30400000000009, w1=14.701700693590038\n",
      "SubSGD iter. 362/499: loss=840.3879365441445, w0=73.31100000000009, w1=14.702627228600186\n",
      "SubSGD iter. 363/499: loss=840.3945357196302, w0=73.30400000000009, w1=14.71044408824219\n",
      "SubSGD iter. 364/499: loss=840.3960639622235, w0=73.30400000000009, w1=14.705838841252877\n",
      "SubSGD iter. 365/499: loss=840.3900044479858, w0=73.30400000000009, w1=14.701233594263565\n",
      "SubSGD iter. 366/499: loss=840.3880601966813, w0=73.31100000000009, w1=14.702160129273713\n",
      "SubSGD iter. 367/499: loss=840.39557893388, w0=73.30400000000009, w1=14.709976988915717\n",
      "SubSGD iter. 368/499: loss=840.3954493600045, w0=73.30400000000009, w1=14.705371741926404\n",
      "SubSGD iter. 369/499: loss=840.3893898457666, w0=73.30400000000009, w1=14.700766494937092\n",
      "SubSGD iter. 370/499: loss=840.3895449784272, w0=73.30400000000009, w1=14.714115136578556\n",
      "SubSGD iter. 371/499: loss=840.4008942720232, w0=73.30400000000009, w1=14.709509889589244\n",
      "SubSGD iter. 372/499: loss=840.3948347577854, w0=73.30400000000009, w1=14.704904642599931\n",
      "SubSGD iter. 373/499: loss=840.3887752435473, w0=73.30400000000009, w1=14.70029939561062\n",
      "SubSGD iter. 374/499: loss=840.3913264474329, w0=73.30400000000009, w1=14.713648037252083\n",
      "SubSGD iter. 375/499: loss=840.4002796698041, w0=73.30400000000009, w1=14.709042790262771\n",
      "SubSGD iter. 376/499: loss=840.3942201555661, w0=73.30400000000009, w1=14.704437543273459\n",
      "SubSGD iter. 377/499: loss=840.3881606413285, w0=73.30400000000009, w1=14.699832296284146\n",
      "SubSGD iter. 378/499: loss=840.3931079164387, w0=73.30400000000009, w1=14.71318093792561\n",
      "SubSGD iter. 379/499: loss=840.3996650675849, w0=73.30400000000009, w1=14.708575690936298\n",
      "SubSGD iter. 380/499: loss=840.3936055533471, w0=73.30400000000009, w1=14.703970443946986\n",
      "SubSGD iter. 381/499: loss=840.3875460391092, w0=73.30400000000009, w1=14.699365196957674\n",
      "SubSGD iter. 382/499: loss=840.3948893854443, w0=73.30400000000009, w1=14.712713838599138\n",
      "SubSGD iter. 383/499: loss=840.3990504653658, w0=73.30400000000009, w1=14.708108591609825\n",
      "SubSGD iter. 384/499: loss=840.3929909511281, w0=73.30400000000009, w1=14.703503344620513\n",
      "SubSGD iter. 385/499: loss=840.3874593386328, w0=73.31100000000009, w1=14.704429879630661\n",
      "SubSGD iter. 386/499: loss=840.390509699605, w0=73.30400000000009, w1=14.712246739272665\n",
      "SubSGD iter. 387/499: loss=840.3984358631467, w0=73.30400000000009, w1=14.707641492283352\n",
      "SubSGD iter. 388/499: loss=840.3923763489088, w0=73.30400000000009, w1=14.70303624529404\n",
      "SubSGD iter. 389/499: loss=840.3875829911699, w0=73.31100000000009, w1=14.703962780304188\n",
      "SubSGD iter. 390/499: loss=840.3915529138546, w0=73.30400000000009, w1=14.711779639946192\n",
      "SubSGD iter. 391/499: loss=840.3978212609275, w0=73.30400000000009, w1=14.70717439295688\n",
      "SubSGD iter. 392/499: loss=840.3917617466898, w0=73.30400000000009, w1=14.702569145967567\n",
      "SubSGD iter. 393/499: loss=840.3877066437067, w0=73.31100000000009, w1=14.703495680977715\n",
      "SubSGD iter. 394/499: loss=840.3925961281043, w0=73.30400000000009, w1=14.71131254061972\n",
      "SubSGD iter. 395/499: loss=840.3972066587085, w0=73.30400000000009, w1=14.706707293630407\n",
      "SubSGD iter. 396/499: loss=840.3911471444706, w0=73.30400000000009, w1=14.702102046641095\n",
      "SubSGD iter. 397/499: loss=840.3878302962436, w0=73.31100000000009, w1=14.703028581651242\n",
      "SubSGD iter. 398/499: loss=840.3936393423539, w0=73.30400000000009, w1=14.710845441293246\n",
      "SubSGD iter. 399/499: loss=840.3965920564895, w0=73.30400000000009, w1=14.706240194303934\n",
      "SubSGD iter. 400/499: loss=840.3905325422515, w0=73.30400000000009, w1=14.701634947314622\n",
      "SubSGD iter. 401/499: loss=840.3879539487805, w0=73.31100000000009, w1=14.70256148232477\n",
      "SubSGD iter. 402/499: loss=840.3946825566037, w0=73.30400000000009, w1=14.710378341966774\n",
      "SubSGD iter. 403/499: loss=840.3959774542702, w0=73.30400000000009, w1=14.705773094977461\n",
      "SubSGD iter. 404/499: loss=840.3899179400323, w0=73.30400000000009, w1=14.701167847988149\n",
      "SubSGD iter. 405/499: loss=840.3880776013173, w0=73.31100000000009, w1=14.702094382998297\n",
      "SubSGD iter. 406/499: loss=840.3957257708535, w0=73.30400000000009, w1=14.7099112426403\n",
      "SubSGD iter. 407/499: loss=840.3953628520511, w0=73.30400000000009, w1=14.705305995650988\n",
      "SubSGD iter. 408/499: loss=840.3893033378131, w0=73.30400000000009, w1=14.700700748661676\n",
      "SubSGD iter. 409/499: loss=840.38979572799, w0=73.30400000000009, w1=14.71404939030314\n",
      "SubSGD iter. 410/499: loss=840.4008077640698, w0=73.30400000000009, w1=14.709444143313828\n",
      "SubSGD iter. 411/499: loss=840.394748249832, w0=73.30400000000009, w1=14.704838896324516\n",
      "SubSGD iter. 412/499: loss=840.3886887355941, w0=73.30400000000009, w1=14.700233649335203\n",
      "SubSGD iter. 413/499: loss=840.3915771969957, w0=73.30400000000009, w1=14.713582290976667\n",
      "SubSGD iter. 414/499: loss=840.4001931618507, w0=73.30400000000009, w1=14.708977043987355\n",
      "SubSGD iter. 415/499: loss=840.3941336476128, w0=73.30400000000009, w1=14.704371796998043\n",
      "SubSGD iter. 416/499: loss=840.388074133375, w0=73.30400000000009, w1=14.69976655000873\n",
      "SubSGD iter. 417/499: loss=840.3933586660014, w0=73.30400000000009, w1=14.713115191650195\n",
      "SubSGD iter. 418/499: loss=840.3995785596317, w0=73.30400000000009, w1=14.708509944660882\n",
      "SubSGD iter. 419/499: loss=840.3935190453938, w0=73.30400000000009, w1=14.70390469767157\n",
      "SubSGD iter. 420/499: loss=840.3874595311559, w0=73.30400000000009, w1=14.699299450682258\n",
      "SubSGD iter. 421/499: loss=840.3951401350072, w0=73.30400000000009, w1=14.712648092323722\n",
      "SubSGD iter. 422/499: loss=840.3989639574124, w0=73.30400000000009, w1=14.70804284533441\n",
      "SubSGD iter. 423/499: loss=840.3929044431745, w0=73.30400000000009, w1=14.703437598345097\n",
      "SubSGD iter. 424/499: loss=840.3874767432687, w0=73.31100000000009, w1=14.704364133355245\n",
      "SubSGD iter. 425/499: loss=840.3906565365785, w0=73.30400000000009, w1=14.712180992997249\n",
      "SubSGD iter. 426/499: loss=840.3983493551932, w0=73.30400000000009, w1=14.707575746007937\n",
      "SubSGD iter. 427/499: loss=840.3922898409554, w0=73.30400000000009, w1=14.702970499018624\n",
      "SubSGD iter. 428/499: loss=840.3876003958057, w0=73.31100000000009, w1=14.703897034028772\n",
      "SubSGD iter. 429/499: loss=840.3916997508281, w0=73.30400000000009, w1=14.711713893670776\n",
      "SubSGD iter. 430/499: loss=840.3977347529742, w0=73.30400000000009, w1=14.707108646681464\n",
      "SubSGD iter. 431/499: loss=840.3916752387363, w0=73.30400000000009, w1=14.702503399692151\n",
      "SubSGD iter. 432/499: loss=840.3877240483428, w0=73.31100000000009, w1=14.7034299347023\n",
      "SubSGD iter. 433/499: loss=840.3927429650778, w0=73.30400000000009, w1=14.711246794344303\n",
      "SubSGD iter. 434/499: loss=840.3971201507551, w0=73.30400000000009, w1=14.706641547354991\n",
      "SubSGD iter. 435/499: loss=840.3910606365172, w0=73.30400000000009, w1=14.702036300365679\n",
      "SubSGD iter. 436/499: loss=840.3878477008795, w0=73.31100000000009, w1=14.702962835375827\n",
      "SubSGD iter. 437/499: loss=840.3937861793274, w0=73.30400000000009, w1=14.71077969501783\n",
      "SubSGD iter. 438/499: loss=840.396505548536, w0=73.30400000000009, w1=14.706174448028518\n",
      "SubSGD iter. 439/499: loss=840.3904460342981, w0=73.30400000000009, w1=14.701569201039206\n",
      "SubSGD iter. 440/499: loss=840.3879713534163, w0=73.31100000000009, w1=14.702495736049354\n",
      "SubSGD iter. 441/499: loss=840.3948293935772, w0=73.30400000000009, w1=14.710312595691358\n",
      "SubSGD iter. 442/499: loss=840.3958909463167, w0=73.30400000000009, w1=14.705707348702045\n",
      "SubSGD iter. 443/499: loss=840.389831432079, w0=73.30400000000009, w1=14.701102101712733\n",
      "SubSGD iter. 444/499: loss=840.388265008547, w0=73.30400000000009, w1=14.714450743354197\n",
      "SubSGD iter. 445/499: loss=840.4013358583356, w0=73.30400000000009, w1=14.709845496364885\n",
      "SubSGD iter. 446/499: loss=840.3952763440976, w0=73.30400000000009, w1=14.705240249375573\n",
      "SubSGD iter. 447/499: loss=840.3892168298598, w0=73.30400000000009, w1=14.70063500238626\n",
      "SubSGD iter. 448/499: loss=840.3900464775527, w0=73.30400000000009, w1=14.713983644027724\n",
      "SubSGD iter. 449/499: loss=840.4007212561164, w0=73.30400000000009, w1=14.709378397038412\n",
      "SubSGD iter. 450/499: loss=840.3946617418785, w0=73.30400000000009, w1=14.7047731500491\n",
      "SubSGD iter. 451/499: loss=840.3886022276406, w0=73.30400000000009, w1=14.700167903059787\n",
      "SubSGD iter. 452/499: loss=840.3918279465586, w0=73.30400000000009, w1=14.713516544701251\n",
      "SubSGD iter. 453/499: loss=840.4001066538973, w0=73.30400000000009, w1=14.70891129771194\n",
      "SubSGD iter. 454/499: loss=840.3940471396594, w0=73.30400000000009, w1=14.704306050722627\n",
      "SubSGD iter. 455/499: loss=840.3879876254216, w0=73.30400000000009, w1=14.699700803733315\n",
      "SubSGD iter. 456/499: loss=840.3936094155642, w0=73.30400000000009, w1=14.713049445374779\n",
      "SubSGD iter. 457/499: loss=840.3994920516782, w0=73.30400000000009, w1=14.708444198385466\n",
      "SubSGD iter. 458/499: loss=840.3934325374403, w0=73.30400000000009, w1=14.703838951396154\n",
      "SubSGD iter. 459/499: loss=840.3873730232024, w0=73.30400000000009, w1=14.699233704406842\n",
      "SubSGD iter. 460/499: loss=840.39539088457, w0=73.30400000000009, w1=14.712582346048306\n",
      "SubSGD iter. 461/499: loss=840.3988774494591, w0=73.30400000000009, w1=14.707977099058994\n",
      "SubSGD iter. 462/499: loss=840.3928179352212, w0=73.30400000000009, w1=14.703371852069681\n",
      "SubSGD iter. 463/499: loss=840.3874941479048, w0=73.31100000000009, w1=14.70429838707983\n",
      "SubSGD iter. 464/499: loss=840.3908033735518, w0=73.30400000000009, w1=14.712115246721833\n",
      "SubSGD iter. 465/499: loss=840.3982628472401, w0=73.30400000000009, w1=14.70750999973252\n",
      "SubSGD iter. 466/499: loss=840.392203333002, w0=73.30400000000009, w1=14.702904752743208\n",
      "SubSGD iter. 467/499: loss=840.3876178004416, w0=73.31100000000009, w1=14.703831287753356\n",
      "SubSGD iter. 468/499: loss=840.3918465878014, w0=73.30400000000009, w1=14.71164814739536\n",
      "SubSGD iter. 469/499: loss=840.3976482450207, w0=73.30400000000009, w1=14.707042900406048\n",
      "SubSGD iter. 470/499: loss=840.3915887307829, w0=73.30400000000009, w1=14.702437653416736\n",
      "SubSGD iter. 471/499: loss=840.3877414529786, w0=73.31100000000009, w1=14.703364188426884\n",
      "SubSGD iter. 472/499: loss=840.3928898020513, w0=73.30400000000009, w1=14.711181048068887\n",
      "SubSGD iter. 473/499: loss=840.3970336428017, w0=73.30400000000009, w1=14.706575801079575\n",
      "SubSGD iter. 474/499: loss=840.3909741285638, w0=73.30400000000009, w1=14.701970554090263\n",
      "SubSGD iter. 475/499: loss=840.3878651055154, w0=73.31100000000009, w1=14.70289708910041\n",
      "SubSGD iter. 476/499: loss=840.3939330163007, w0=73.30400000000009, w1=14.710713948742415\n",
      "SubSGD iter. 477/499: loss=840.3964190405826, w0=73.30400000000009, w1=14.706108701753102\n",
      "SubSGD iter. 478/499: loss=840.3903595263446, w0=73.30400000000009, w1=14.70150345476379\n",
      "SubSGD iter. 479/499: loss=840.3879887580525, w0=73.31100000000009, w1=14.702429989773938\n",
      "SubSGD iter. 480/499: loss=840.3949762305506, w0=73.30400000000009, w1=14.710246849415942\n",
      "SubSGD iter. 481/499: loss=840.3958044383634, w0=73.30400000000009, w1=14.70564160242663\n",
      "SubSGD iter. 482/499: loss=840.3897449241256, w0=73.30400000000009, w1=14.701036355437317\n",
      "SubSGD iter. 483/499: loss=840.3885157581099, w0=73.30400000000009, w1=14.714384997078781\n",
      "SubSGD iter. 484/499: loss=840.4012493503822, w0=73.30400000000009, w1=14.709779750089469\n",
      "SubSGD iter. 485/499: loss=840.3951898361443, w0=73.30400000000009, w1=14.705174503100157\n",
      "SubSGD iter. 486/499: loss=840.3891303219064, w0=73.30400000000009, w1=14.700569256110844\n",
      "SubSGD iter. 487/499: loss=840.3902972271155, w0=73.30400000000009, w1=14.713917897752308\n",
      "SubSGD iter. 488/499: loss=840.400634748163, w0=73.30400000000009, w1=14.709312650762996\n",
      "SubSGD iter. 489/499: loss=840.3945752339253, w0=73.30400000000009, w1=14.704707403773684\n",
      "SubSGD iter. 490/499: loss=840.3885157196872, w0=73.30400000000009, w1=14.700102156784371\n",
      "SubSGD iter. 491/499: loss=840.3920786961212, w0=73.30400000000009, w1=14.713450798425836\n",
      "SubSGD iter. 492/499: loss=840.4000201459439, w0=73.30400000000009, w1=14.708845551436523\n",
      "SubSGD iter. 493/499: loss=840.393960631706, w0=73.30400000000009, w1=14.704240304447211\n",
      "SubSGD iter. 494/499: loss=840.3879011174681, w0=73.30400000000009, w1=14.699635057457899\n",
      "SubSGD iter. 495/499: loss=840.3938601651271, w0=73.30400000000009, w1=14.712983699099363\n",
      "SubSGD iter. 496/499: loss=840.3994055437248, w0=73.30400000000009, w1=14.70837845211005\n",
      "SubSGD iter. 497/499: loss=840.3933460294869, w0=73.30400000000009, w1=14.703773205120738\n",
      "SubSGD iter. 498/499: loss=840.3873879000039, w0=73.31100000000009, w1=14.704699740130886\n",
      "SubSGD iter. 499/499: loss=840.3899069962754, w0=73.30400000000009, w1=14.71251659977289\n",
      "SubSGD: execution time=0.017 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed21e3ef3244a919e4bc70223c8d203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
